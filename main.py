import os
import logging
import pandas as pd
from fastapi import FastAPI, HTTPException, Depends
from elasticsearch import Elasticsearch
from sentence_transformers import SentenceTransformer

# RAG Analyzer ëª¨ë“ˆì—ì„œ í•µì‹¬ ì»´í¬ë„ŒíŠ¸ë“¤ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.
from rag_query_analyzer.config import get_config, Config
from rag_query_analyzer.analyzers.main_analyzer import AdvancedRAGQueryAnalyzer
from rag_query_analyzer.models import SearchResult
from rag_query_analyzer.data_processing import process_survey_data
from rag_query_analyzer.utils.elasticsearch import create_index_if_not_exists, bulk_index_data

# --- ë¡œê¹… ì„¤ì • ---
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# --- ì„¤ì • ë° ì „ì—­ ê°ì²´ ì´ˆê¸°í™” ---
try:
    config = get_config()
    app = FastAPI(
        title="Advanced RAG Survey Search API",
        description="ì§€ëŠ¥í˜• ì¿¼ë¦¬ ë¶„ì„ê³¼ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰, ë¦¬ë­í‚¹ì„ ì§€ì›í•˜ëŠ” ì„¤ë¬¸ì¡°ì‚¬ ê²€ìƒ‰ API",
        version="2.0.0 (Auto-indexing)"
    )

    # Elasticsearch í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
    es_client = Elasticsearch(config.ES_HOST, request_timeout=30)

    # ì„ë² ë”© ëª¨ë¸ ë¡œë”©
    logger.info(f"ì„ë² ë”© ëª¨ë¸ ë¡œë”© ì¤‘: {config.EMBEDDING_MODEL}")
    embedding_model = SentenceTransformer(config.EMBEDDING_MODEL)

    # ì¿¼ë¦¬ ë¶„ì„ê¸° ì´ˆê¸°í™”
    logger.info("ì¿¼ë¦¬ ë¶„ì„ê¸° ì´ˆê¸°í™” ì¤‘...")
    analyzer = AdvancedRAGQueryAnalyzer(config)

except Exception as e:
    logger.critical(f"ğŸš¨ ì• í”Œë¦¬ì¼€ì´ì…˜ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}", exc_info=True)
    raise

# --- FastAPI ì‹œì‘ ì´ë²¤íŠ¸ ---
@app.on_event("startup")
async def startup_event():
    """ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹œì‘ ì‹œ ë°ì´í„° ìë™ ìƒ‰ì¸"""
    index_name = "survey_responses" # ê³ ì •ëœ ì¸ë±ìŠ¤ ì´ë¦„
    response_file = "./data/survey_welcome2.csv"

    logger.info("--- ğŸš€ ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹œì‘: ìë™ ìƒ‰ì¸ì„ ì¤€ë¹„í•©ë‹ˆë‹¤. (ë‹¨ì¼ íŒŒì¼ ëª¨ë“œ) ---")
    
    try:
        if not es_client.ping():
            logger.error("ğŸš¨ Elasticsearch ì„œë²„ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ìƒ‰ì¸ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
            return

        # ì¸ë±ìŠ¤ê°€ ì´ë¯¸ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
        if es_client.indices.exists(index=index_name):
            # ë¬¸ì„œ ê°œìˆ˜ í™•ì¸ìœ¼ë¡œ ì´ë¯¸ ìƒ‰ì¸ë˜ì—ˆëŠ”ì§€ ì¶”ì •
            count = es_client.count(index=index_name)['count']
            if count > 0:
                logger.info(f"ğŸ‘ '{index_name}' ì¸ë±ìŠ¤ì— ì´ë¯¸ {count}ê°œì˜ ë¬¸ì„œê°€ ì¡´ì¬í•©ë‹ˆë‹¤. ìƒ‰ì¸ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
                return
            else:
                logger.info(f"ğŸ—‘ï¸ '{index_name}' ì¸ë±ìŠ¤ê°€ ë¹„ì–´ìˆì–´ ìƒˆë¡œ ìƒ‰ì¸í•©ë‹ˆë‹¤.")
        
        logger.info(f"ğŸ“‚ ë°ì´í„° íŒŒì¼ í™•ì¸: {response_file}")
        if not os.path.exists(response_file):
            logger.warning(f"ğŸš¨ data í´ë”ì— {os.path.basename(response_file)} íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
            logger.warning("   - í”„ë¡œì íŠ¸ ë£¨íŠ¸ì— 'data' í´ë”ë¥¼ ìƒì„±í•˜ê³  íŒŒì¼ì„ ë„£ì–´ì£¼ì„¸ìš”.")
            return

        # ë°ì´í„° ì²˜ë¦¬ ë° ìƒ‰ì¸ ì‹¤í–‰
        create_index_if_not_exists(es_client, index_name)
        df_responses = pd.read_csv(response_file, encoding="utf-8-sig")
        df_responses = df_responses.astype(object).where(pd.notnull(df_responses), None)

        actions = process_survey_data(df_responses, embedding_model, index_name)
        
        if not actions:
            logger.warning("âš ï¸ ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return

        success, failed = bulk_index_data(es_client, actions)
        logger.info(f"ğŸ‰ ìë™ ìƒ‰ì¸ ì™„ë£Œ! ì„±ê³µ: {success}, ì‹¤íŒ¨: {len(failed)}")

    except Exception as e:
        logger.error(f"ğŸš¨ ì‹œì‘ ì‹œ ë°ì´í„° ìƒ‰ì¸ ì‹¤íŒ¨: {e}", exc_info=True)

# --- API ì—”ë“œí¬ì¸íŠ¸ ---

@app.get("/", summary="API í™˜ì˜ ë©”ì‹œì§€")
def read_root():
    return {"message": "Advanced RAG Survey Search API (Auto-indexing)ì— ì˜¤ì‹  ê²ƒì„ í™˜ì˜í•©ë‹ˆë‹¤!"}


@app.get("/intelligent-search/", summary="ì§€ëŠ¥í˜• ì„¤ë¬¸ ê²€ìƒ‰")
def intelligent_search(
    query: str,
    index_name: str = "survey_responses", # ê¸°ë³¸ ì¸ë±ìŠ¤ ì´ë¦„ ê³ ì •
    context: str = "",
    cfg: Config = Depends(get_config)
):
    """
    ìì—°ì–´ ì¿¼ë¦¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ì„¤ë¬¸ ë°ì´í„°ë¥¼ ì§€ëŠ¥ì ìœ¼ë¡œ ê²€ìƒ‰í•©ë‹ˆë‹¤.
    - **query**: ê²€ìƒ‰í•  ìì—°ì–´ ì¿¼ë¦¬ (ì˜ˆ: "30ëŒ€ ë‚¨ì„± ì¤‘ ìŠ¤íŠ¸ë ˆìŠ¤ì— ë§Œì¡±í•˜ëŠ” ì‚¬ëŒ")
    - **index_name**: ê²€ìƒ‰í•  ëŒ€ìƒ ì¸ë±ìŠ¤ (ê¸°ë³¸ê°’: survey_responses)
    - **context**: ê²€ìƒ‰ì— ë„ì›€ì´ ë  ì¶”ê°€ì ì¸ ë§¥ë½ ì •ë³´
    """
    if not es_client.indices.exists(index=index_name):
        raise HTTPException(status_code=404, detail=f"ì¸ë±ìŠ¤ '{index_name}'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì„œë²„ ì‹œì‘ ì‹œ ìƒ‰ì¸ì´ ì™„ë£Œë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")

    try:
        # 1. ì¿¼ë¦¬ ë¶„ì„
        analysis = analyzer.analyze_query(query, context)

        # 2. ì¿¼ë¦¬ ì„ë² ë”© ìƒì„±
        query_vector = embedding_model.encode(query).tolist()

        # 3. Elasticsearch ì¿¼ë¦¬ ë¹Œë“œ
        es_query = analyzer.build_search_query(
            analysis, query_vector, size=cfg.INITIAL_SEARCH_SIZE
        )
        
        # 4. 1ì°¨ ê²€ìƒ‰ ì‹¤í–‰
        response = es_client.search(
            index=index_name, 
            body=es_query
        )
        
        initial_hits = response["hits"]["hits"]
        search_results = [
            SearchResult(
                doc_id=hit["_id"],
                score=hit["_score"],
                summary=hit.get("_source", {}).get("user_id", ""), # ê°„ë‹¨í•œ ìš”ì•½
                answers=hit.get("_source", {})
            )
            for hit in initial_hits
        ]

        # 5. ë¦¬ë­í‚¹
        final_results = analyzer.rerank_results(query, search_results)

        return {
            "query": query,
            "query_analysis": analysis.to_dict(),
            "search_stats": {
                "initial_candidates": len(search_results),
                "final_results": len(final_results),
                "reranking_enabled": analyzer.reranker is not None
            },
            "results": [res.to_dict() for res in final_results]
        }

    except Exception as e:
        logger.error(f"ì§€ëŠ¥í˜• ê²€ìƒ‰ ì˜¤ë¥˜: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

@app.get("/system-status/", summary="ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸")
def system_status(cfg: Config = Depends(get_config)):
    """
    RAG ì‹œìŠ¤í…œì˜ ì£¼ìš” êµ¬ì„± ìš”ì†Œ ìƒíƒœë¥¼ í™•ì¸í•©ë‹ˆë‹¤.
    """
    return {
        "status": {
            "elasticsearch_connection": "connected" if es_client.ping() else "disconnected",
            "query_analyzer_initialized": "ok" if analyzer else "failed",
            "embedding_model_loaded": cfg.EMBEDDING_MODEL,
            "reranker_enabled": cfg.ENABLE_RERANKING,
            "reranker_model_loaded": cfg.RERANKER_MODEL if cfg.ENABLE_RERANKING else "N/A",
            "cache_enabled": cfg.ENABLE_CACHE,
            "claude_model": cfg.CLAUDE_MODEL
        }
    }

if __name__ == "__main__":
    import uvicorn
    logger.info("ğŸš€ FastAPI ì„œë²„ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...")
    uvicorn.run(app, host="0.0.0.0", port=8000)