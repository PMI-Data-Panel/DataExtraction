"""
OpenSearch ì¸ë±ìŠ¤ ê´€ë¦¬ ëª¨ë“ˆ
"""

from opensearchpy import OpenSearch
from fastapi import HTTPException
import logging
from typing import Optional

logger = logging.getLogger(__name__)


def create_survey_index(
    os_client: OpenSearch,
    index_name: str,
    force_recreate: bool = False,
    number_of_shards: int = 3,
    number_of_replicas: int = 1
) -> bool:
    """
    OpenSearchì— ì„¤ë¬¸ì¡°ì‚¬ ë°ì´í„°ìš© ì¸ë±ìŠ¤ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

    Args:
        os_client: OpenSearch í´ë¼ì´ì–¸íŠ¸
        index_name: ìƒì„±í•  ì¸ë±ìŠ¤ ì´ë¦„
        force_recreate: ê¸°ì¡´ ì¸ë±ìŠ¤ ê°•ì œ ì‚­ì œ ì—¬ë¶€
        number_of_shards: ìƒ¤ë“œ ê°œìˆ˜ (ë°ì´í„° ê·œëª¨ì— ë”°ë¼ ì¡°ì •)
        number_of_replicas: ë³µì œë³¸ ê°œìˆ˜

    Returns:
        ì¸ë±ìŠ¤ ìƒì„±/ìœ ì§€ ì„±ê³µ ì—¬ë¶€
    """

    # ê¸°ì¡´ ì¸ë±ìŠ¤ ì¡´ì¬ í™•ì¸
    if os_client.indices.exists(index=index_name):
        if force_recreate:
            logger.warning(f"âš ï¸ '{index_name}' ì¸ë±ìŠ¤ë¥¼ ê°•ì œ ì‚­ì œí•©ë‹ˆë‹¤.")
            try:
                os_client.indices.delete(index=index_name)
                logger.info(f"ğŸ—‘ï¸ ê¸°ì¡´ '{index_name}' ì¸ë±ìŠ¤ë¥¼ ì‚­ì œí–ˆìŠµë‹ˆë‹¤.")
            except Exception as e:
                logger.error(f"ğŸš¨ ê¸°ì¡´ '{index_name}' ì¸ë±ìŠ¤ ì‚­ì œ ì‹¤íŒ¨: {e}")
                raise HTTPException(status_code=500, detail=f"ê¸°ì¡´ ì¸ë±ìŠ¤ ì‚­ì œ ì‹¤íŒ¨: {e}")
        else:
            logger.info(f"â„¹ï¸ '{index_name}' ì¸ë±ìŠ¤ê°€ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤. ê¸°ì¡´ ì¸ë±ìŠ¤ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            return True

    logger.info(f"âœ¨ '{index_name}' ì¸ë±ìŠ¤ë¥¼ ìƒˆë¡œ ìƒì„±í•©ë‹ˆë‹¤.")

    # ë§¤í•‘ ì •ì˜
    mappings = {
        "properties": {
            "user_id": {
                "type": "keyword"
            },
            "timestamp": {
                "type": "date"
            },
            "qa_pairs": {
                "type": "nested",
                "properties": {
                    "q_code": {
                        "type": "keyword"
                    },
                    "q_text": {
                        "type": "text",
                        "analyzer": "nori_analyzer",
                        "fields": {
                            "keyword": {
                                "type": "keyword",
                                "ignore_above": 256
                            }
                        }
                    },
                    "q_type": {
                        "type": "keyword"
                    },
                    "answer_text": {
                        "type": "text",
                        "analyzer": "nori_analyzer",
                        "fields": {
                            "keyword": {
                                "type": "keyword",
                                "ignore_above": 256
                            }
                        }
                    },
                    "embedding_text": {
                        "type": "text",
                        "analyzer": "nori_analyzer"
                    },
                    "answer_vector": {
                        "type": "knn_vector",
                        "dimension": 1024,  # KURE-v1 ì°¨ì›
                        "method": {
                            "name": "hnsw",
                            "engine": "lucene",
                            "space_type": "cosinesimil",
                            "parameters": {
                                "ef_construction": 128,
                                "m": 24
                            }
                        }
                    }
                }
            },
        }
    }

    # ì¸ë±ìŠ¤ ì„¤ì •
    settings = {
        "number_of_shards": number_of_shards,
        "number_of_replicas": number_of_replicas,
        "refresh_interval": "30s",  # ìƒ‰ì¸ ì¤‘ ì„±ëŠ¥ í–¥ìƒ (ì™„ë£Œ í›„ ë³€ê²½)
        "analysis": {
            "analyzer": {
                "nori_analyzer": {
                    "type": "custom",
                    "tokenizer": "nori_tokenizer",
                    "filter": ["nori_posfilter", "lowercase", "nori_readingform"]
                }
            },
            "tokenizer": {
                "nori_tokenizer": {
                    "type": "nori_tokenizer",
                    "decompound_mode": "mixed"  # ë³µí•©ì–´ ë¶„í•´ ëª¨ë“œ
                }
            },
            "filter": {
                "nori_posfilter": {
                    "type": "nori_part_of_speech",
                    # ë¶ˆí•„ìš”í•œ í’ˆì‚¬ ì œê±° (ì¡°ì‚¬, ì–´ë¯¸, ì ‘ë¯¸ì‚¬ ë“±)
                    "stoptags": [
                        "E", "IC", "J", "MAG", "MM", "SP", "SSC",
                        "SSO", "SC", "SE", "XPN", "XSA", "XSN",
                        "XSV", "UNA", "NA", "VSV"
                    ]
                }
            }
        }
    }

    try:
        body = {
            "settings": settings,
            "mappings": mappings
        }

        response = os_client.indices.create(index=index_name, body=body)
        logger.info(f"ğŸ‘ '{index_name}' ì¸ë±ìŠ¤ ìƒì„± ì™„ë£Œ")
        logger.debug(f"   ì‘ë‹µ: {response}")

        return True

    except Exception as e:
        logger.error(f"ğŸš¨ '{index_name}' ì¸ë±ìŠ¤ ìƒì„± ì‹¤íŒ¨: {e}", exc_info=True)
        raise HTTPException(
            status_code=500,
            detail=f"'{index_name}' ì¸ë±ìŠ¤ ìƒì„± ì‹¤íŒ¨: {str(e)}"
        )


def update_index_refresh_interval(
    os_client: OpenSearch,
    index_name: str,
    interval: str = "1s"
) -> None:
    """
    ì¸ë±ìŠ¤ì˜ refresh_interval ì„¤ì •ì„ ë³€ê²½í•©ë‹ˆë‹¤.
    ëŒ€ëŸ‰ ìƒ‰ì¸ í›„ ê²€ìƒ‰ ì„±ëŠ¥ì„ ìœ„í•´ ê¸°ë³¸ê°’ìœ¼ë¡œ ë³µêµ¬í•  ë•Œ ì‚¬ìš©.

    Args:
        os_client: OpenSearch í´ë¼ì´ì–¸íŠ¸
        index_name: ì¸ë±ìŠ¤ ì´ë¦„
        interval: refresh ê°„ê²© (ì˜ˆ: "1s", "30s", "-1" for ë¹„í™œì„±í™”)
    """
    try:
        os_client.indices.put_settings(
            index=index_name,
            body={"index": {"refresh_interval": interval}}
        )
        logger.info(f"âœ… '{index_name}' ì¸ë±ìŠ¤ì˜ refresh_intervalì„ '{interval}'ë¡œ ë³€ê²½í–ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        logger.error(f"âš ï¸ refresh_interval ë³€ê²½ ì‹¤íŒ¨: {e}")


def get_index_stats(os_client: OpenSearch, index_name: str) -> Optional[dict]:
    """
    ì¸ë±ìŠ¤ì˜ í†µê³„ ì •ë³´ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤.

    Args:
        os_client: OpenSearch í´ë¼ì´ì–¸íŠ¸
        index_name: ì¸ë±ìŠ¤ ì´ë¦„

    Returns:
        ì¸ë±ìŠ¤ í†µê³„ ì •ë³´ ë˜ëŠ” None
    """
    try:
        stats = os_client.indices.stats(index=index_name)
        doc_count = stats['indices'][index_name]['total']['docs']['count']
        size_in_bytes = stats['indices'][index_name]['total']['store']['size_in_bytes']
        size_in_mb = size_in_bytes / (1024 * 1024)

        logger.info(f"ğŸ“Š '{index_name}' ì¸ë±ìŠ¤ í†µê³„:")
        logger.info(f"   ë¬¸ì„œ ìˆ˜: {doc_count:,}")
        logger.info(f"   í¬ê¸°: {size_in_mb:.2f} MB")

        return {
            'doc_count': doc_count,
            'size_bytes': size_in_bytes,
            'size_mb': size_in_mb
        }
    except Exception as e:
        logger.error(f"âš ï¸ ì¸ë±ìŠ¤ í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        return None


def force_merge_index(os_client: OpenSearch, index_name: str, max_num_segments: int = 1) -> None:
    """
    ì¸ë±ìŠ¤ë¥¼ force mergeí•˜ì—¬ ê²€ìƒ‰ ì„±ëŠ¥ì„ ìµœì í™”í•©ë‹ˆë‹¤.
    ëŒ€ëŸ‰ ìƒ‰ì¸ ì™„ë£Œ í›„ í•œ ë²ˆë§Œ ì‹¤í–‰ ê¶Œì¥.

    Args:
        os_client: OpenSearch í´ë¼ì´ì–¸íŠ¸
        index_name: ì¸ë±ìŠ¤ ì´ë¦„
        max_num_segments: ìµœëŒ€ ì„¸ê·¸ë¨¼íŠ¸ ìˆ˜
    """
    try:
        logger.info(f"ğŸ”§ '{index_name}' ì¸ë±ìŠ¤ force merge ì‹œì‘...")
        os_client.indices.forcemerge(
            index=index_name,
            max_num_segments=max_num_segments,
            wait_for_completion=True
        )
        logger.info(f"âœ… force merge ì™„ë£Œ")
    except Exception as e:
        logger.error(f"âš ï¸ force merge ì‹¤íŒ¨: {e}")
