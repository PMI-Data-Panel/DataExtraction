"""OpenSearch í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì¿¼ë¦¬ ë¹Œë” (RRF ê¸°ë°˜)"""
import logging
from typing import List, Dict, Optional, Any

logger = logging.getLogger(__name__)


class OpenSearchHybridQueryBuilder:
    """
    RRF (Reciprocal Rank Fusion) ê¸°ë°˜ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰

    í‚¤ì›Œë“œ ê²€ìƒ‰ê³¼ ë²¡í„° ê²€ìƒ‰ ê²°ê³¼ë¥¼ RRF ì•Œê³ ë¦¬ì¦˜ìœ¼ë¡œ ê²°í•©í•˜ì—¬
    ì§„ì •í•œ í•˜ì´ë¸Œë¦¬ë“œ ì ìˆ˜ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    """

    def __init__(self, config=None):
        self.config = config

        # RRF íŒŒë¼ë¯¸í„°
        self.rrf_k = 60  # RRF ìƒìˆ˜ (ì¼ë°˜ì ìœ¼ë¡œ 60)

        # ì¸êµ¬í†µê³„ íŒ¨í„´ (ì •ê·œí™” ë§¤í•‘)
        self.demographic_patterns = {
            "age_group": {
                "values": ["10ëŒ€", "20ëŒ€", "30ëŒ€", "40ëŒ€", "50ëŒ€", "60ëŒ€", "70ëŒ€"],
                "synonyms": {}
            },
            "gender": {
                "values": ["ë‚¨ì„±", "ì—¬ì„±"],
                "synonyms": {"ë‚¨ì": "ë‚¨ì„±", "ì—¬ì": "ì—¬ì„±", "ë‚¨": "ë‚¨ì„±", "ì—¬": "ì—¬ì„±"}
            },
            "region": {
                "values": ["ì„œìš¸", "ë¶€ì‚°", "ëŒ€êµ¬", "ì¸ì²œ", "ê´‘ì£¼", "ëŒ€ì „", "ìš¸ì‚°", "ì„¸ì¢…"],
                "synonyms": {"ì„œìš¸ì‹œ": "ì„œìš¸", "ë¶€ì‚°ì‹œ": "ë¶€ì‚°"}
            }
        }

    def build_query(
        self,
        analysis,  # QueryAnalysis ê°ì²´
        query_vector: Optional[List[float]] = None,
        size: int = 10
    ) -> Dict[str, Any]:
        """
        í•˜ì´ë¸Œë¦¬ë“œ ì¿¼ë¦¬ ìƒì„±

        Args:
            analysis: QueryAnalysis ê°ì²´ (must_terms, should_terms, intent ë“± í¬í•¨)
            query_vector: ì¿¼ë¦¬ ì„ë² ë”© ë²¡í„°
            size: ë°˜í™˜í•  ë¬¸ì„œ ê°œìˆ˜

        Returns:
            OpenSearch ì¿¼ë¦¬ DSL
        """

        # 1. ì¸êµ¬í†µê³„ í•„í„° ì¶”ì¶œ
        demographic_filters = self._extract_demographic_filters(analysis)

        # 2. ì˜ë¯¸ì  í‚¤ì›Œë“œ ì¶”ì¶œ (ì¸êµ¬í†µê³„ ì œì™¸)
        semantic_terms = self._extract_semantic_terms(analysis)

        # 3. ì¿¼ë¦¬ ì „ëµ ì„ íƒ
        if query_vector and analysis.intent in ["hybrid", "semantic_search"]:
            # í•˜ì´ë¸Œë¦¬ë“œ: í‚¤ì›Œë“œ + ë²¡í„°
            return self._build_hybrid_query(
                semantic_terms,
                query_vector,
                demographic_filters,
                size,
                analysis.alpha
            )
        else:
            # í‚¤ì›Œë“œë§Œ
            return self._build_keyword_only_query(
                semantic_terms,
                demographic_filters,
                size
            )

    # Compatibility wrapper for existing call sites
    def build_complete_request(
        self,
        analysis,
        query_vector: Optional[List[float]] = None,
        size: int = 10,
        filters: Optional[List[Dict]] = None
    ) -> Dict[str, Any]:
        """Compat: delegate to build_query; filters are currently encoded in analysis."""
        return self.build_query(analysis, query_vector=query_vector, size=size)

    def _extract_demographic_filters(self, analysis) -> List[str]:
        """ë¶„ì„ ê²°ê³¼ì—ì„œ ì¸êµ¬í†µê³„ í•„í„° í›„ë³´ ì¶”ì¶œ"""
        demographic_terms: List[str] = []

        entities = getattr(analysis, "demographic_entities", None)
        if entities:
            for entity in entities:
                demographic_terms.append(str(entity.raw_value))
                demographic_terms.append(str(entity.value))
                for syn in getattr(entity, "synonyms", []) or []:
                    demographic_terms.append(str(syn))
        else:
            for term in analysis.must_terms:
                matched = False
                for field, config in self.demographic_patterns.items():
                    if term in config["values"]:
                        demographic_terms.append(term)
                        matched = True
                        break
                    if term in config["synonyms"]:
                        normalized = config["synonyms"][term]
                        demographic_terms.append(normalized)
                        matched = True
                        break
                if not matched:
                    logger.debug(f"'{term}'ì€(ëŠ”) ì¸êµ¬í†µê³„ í‚¤ì›Œë“œê°€ ì•„ë‹˜")

        # ì¤‘ë³µ ì œê±° ë° ì •ë¦¬
        seen = set()
        unique_terms: List[str] = []
        for term in demographic_terms:
            if not term:
                continue
            lowered = term.lower()
            if lowered in seen:
                continue
            seen.add(lowered)
            unique_terms.append(term)

        return unique_terms

    def _extract_semantic_terms(self, analysis) -> Dict[str, List[str]]:
        """ì¸êµ¬í†µê³„ê°€ ì•„ë‹Œ ì˜ë¯¸ì  í‚¤ì›Œë“œ ì¶”ì¶œ"""
        all_demographic_values = set()
        for field_config in self.demographic_patterns.values():
            all_demographic_values.update(field_config["values"])
            all_demographic_values.update(field_config["synonyms"].keys())

        must_semantic = [
            term for term in analysis.must_terms
            if term not in all_demographic_values
        ]

        should_semantic = [
            term for term in analysis.should_terms
            if term not in all_demographic_values
        ]

        return {
            "must": must_semantic,
            "should": should_semantic,
            "must_not": analysis.must_not_terms
        }

    def _build_hybrid_query(
        self,
        semantic_terms: Dict[str, List[str]],
        query_vector: List[float],
        demographic_filters: List[Dict],
        size: int,
        alpha: float
    ) -> Dict[str, Any]:
        """
        RRF ê¸°ë°˜ í•˜ì´ë¸Œë¦¬ë“œ ì¿¼ë¦¬

        ì „ëµ:
        1. í‚¤ì›Œë“œ ê²€ìƒ‰ ê²°ê³¼ ì–»ê¸° (nested bool)
        2. ë²¡í„° ê²€ìƒ‰ ê²°ê³¼ ì–»ê¸° (kNN)
        3. OpenSearchì˜ RRFë¡œ ê²°í•© (v2.10+)
        """

        # í‚¤ì›Œë“œ ê²€ìƒ‰ ì¿¼ë¦¬
        keyword_query = self._build_keyword_search(
            semantic_terms,
            demographic_filters
        )

        # ë²¡í„° ê²€ìƒ‰ ì¿¼ë¦¬
        vector_query = self._build_vector_search(
            query_vector,
            demographic_filters,
            size
        )

        # RRF ê²°í•© (OpenSearch 2.10+)
        if hasattr(self.config, 'OPENSEARCH_VERSION') and self.config.OPENSEARCH_VERSION >= 2.10:
            # ë‚´ì¥ RRF ì‚¬ìš©
            query = {
                "query": {
                    "hybrid": {
                        "queries": [
                            keyword_query,
                            vector_query
                        ]
                    }
                },
                "size": size,
                "ext": {
                    "rrf": {
                        "rank_constant": self.rrf_k,
                        "window_size": size * 2
                    }
                }
            }
        else:
            # Fallback: ê°€ì¤‘ í‰ê·  ë°©ì‹
            query = self._build_weighted_hybrid(
                keyword_query,
                vector_query,
                alpha,
                size
            )

        return query

    def _build_keyword_search(
        self,
        semantic_terms: Dict[str, List[str]],
        demographic_filters: List[str]
    ) -> Dict:
        """í‚¤ì›Œë“œ ê²€ìƒ‰ ì¿¼ë¦¬ (qa_pairs nestedì—ì„œ ê²€ìƒ‰, ê° í‚¤ì›Œë“œëŠ” ì„œë¡œ ë‹¤ë¥¸ qa_pairì—ì„œ ê²€ìƒ‰)
        
        âš ï¸ ì¤‘ìš”: Demographics í‚¤ì›Œë“œëŠ” í•„í„°ë¡œë§Œ ì²˜ë¦¬í•˜ê³ , semantic_termsì—ì„œ ì œì™¸
        """

        must_queries = []
        
        # Demographics í‚¤ì›Œë“œ ì§‘í•© (ì¤‘ë³µ ë°©ì§€ìš©)
        demographic_set = set(demographic_filters)

        # â­ 1. Demographicsë§Œ must ì¡°ê±´ìœ¼ë¡œ (ê°ê° ë…ë¦½)
        #    - demographic_filtersëŠ” í•„í„°ë¡œë§Œ ì²˜ë¦¬ (ì´ë¯¸ í•„í„°ë¡œ ì ìš©ë¨)
        #    - ì—¬ê¸°ì„œëŠ” í‚¤ì›Œë“œ ê²€ìƒ‰ì—ì„œ ì œì™¸í•˜ë¯€ë¡œ ì¶”ê°€í•˜ì§€ ì•ŠìŒ

        # â­ 2. ì˜ë¯¸ì  must í‚¤ì›Œë“œ (Demographicsê°€ ì•„ë‹Œ ê²ƒë§Œ)
        # âœ¨ ê°œì„ : ëª¨ë“  must_termsë¥¼ í•˜ë‚˜ì˜ nested ì¿¼ë¦¬ë¡œ í†µí•© (ì„±ëŠ¥ í–¥ìƒ)
        must_terms_filtered = [
            term for term in semantic_terms["must"]
            if term not in demographic_set
        ]

        if must_terms_filtered:
            # â­ ê°œì„ : answerì™€ answer_text ë‘˜ ë‹¤ ê²€ìƒ‰ (s_welcome_*ëŠ” answerë§Œ, qpoll_*ëŠ” answer_textë„)
            # ëª¨ë“  must_termsë¥¼ í•˜ë‚˜ì˜ nested ì¿¼ë¦¬ ë‚´ë¶€ì˜ bool.mustë¡œ ì²˜ë¦¬
            must_queries.append({
                "nested": {
                    "path": "qa_pairs",
                    "query": {
                        "bool": {
                            "must": [
                                {
                                    "bool": {
                                        "should": [
                                            {"match": {"qa_pairs.answer": term}},           # s_welcome_* (í•„ìˆ˜)
                                            {"match": {"qa_pairs.answer_text": term}}      # qpoll_* (ì˜µì…˜)
                                        ],
                                        "minimum_should_match": 1
                                    }
                                }
                                for term in must_terms_filtered
                            ]
                        }
                    },
                    "score_mode": "max",
                    # inner_hitsëŠ” ì œê±° (ì„±ëŠ¥ í–¥ìƒ, í•„ìš”ì‹œ í›„ì²˜ë¦¬ì—ì„œ ì¶”ì¶œ)
                }
            })

        # â­ 3. should ì¡°ê±´ (Demographics ì œì™¸, ìˆì„ ë•Œë§Œ)
        should_query = None
        if semantic_terms["should"]:
            # Demographics ì œì™¸
            should_terms_filtered = [
                term for term in semantic_terms["should"]
                if term not in demographic_set
            ]

            if should_terms_filtered:
                should_query = {
                    "nested": {
                        "path": "qa_pairs",
                        "query": {
                            "bool": {
                                "should": [
                                    {
                                        "bool": {
                                            "should": [
                                                {"match": {"qa_pairs.answer": term}},           # s_welcome_*
                                                {"match": {"qa_pairs.answer_text": term}}      # qpoll_*
                                            ],
                                            "minimum_should_match": 1
                                        }
                                    }
                                    for term in should_terms_filtered
                                ],
                                "minimum_should_match": 1
                            }
                        },
                        "score_mode": "max",
                        # inner_hits ì œê±° (ì„±ëŠ¥ í–¥ìƒ)
                    }
                }

        # â­ 4. ìµœì¢… ì¿¼ë¦¬ êµ¬ì„±
        if must_queries or should_query:
            bool_parts = {}

            if must_queries:
                bool_parts["must"] = must_queries

            if should_query:
                bool_parts["should"] = [should_query]

            # must_not ì¡°ê±´
            if semantic_terms["must_not"]:
                bool_parts["must_not"] = [
                    {
                        "nested": {
                            "path": "qa_pairs",
                            "query": {
                                "bool": {
                                    "should": [
                                        {"match": {"qa_pairs.answer": term}},           # s_welcome_*
                                        {"match": {"qa_pairs.answer_text": term}}      # qpoll_*
                                    ],
                                    "minimum_should_match": 1
                                }
                            }
                        }
                    }
                    for term in semantic_terms["must_not"]
                    if term not in demographic_set  # Demographics ì œì™¸
                ]

            query = {
                "bool": bool_parts
            }
        else:
            # â­ match_all ë°˜í™˜í•˜ì§€ ì•ŠìŒ (í•„í„°ë§Œ ìˆëŠ” ê²½ìš°ë¥¼ ìœ„í•´)
            # Noneì„ ë°˜í™˜í•˜ë©´ í˜¸ì¶œìê°€ í•„í„°ë§Œ ì‚¬ìš©í•  ìˆ˜ ìˆìŒ
            query = None

        logger.info(f"ğŸ” ìƒì„±ëœ ì¿¼ë¦¬ êµ¬ì¡°:")
        logger.info(f"  - Must ì¡°ê±´: {len(must_queries)}ê°œ (Demographics ì œì™¸)")
        logger.info(f"  - Should ì¡°ê±´: {'ìˆìŒ' if should_query else 'ì—†ìŒ'}")
        logger.info(f"  - Demographics í•„í„°: {len(demographic_filters)}ê°œ (ë³„ë„ í•„í„°ë¡œ ì²˜ë¦¬)")
        if query is None:
            logger.info(f"  - âš ï¸ í‚¤ì›Œë“œ ì¿¼ë¦¬ ì—†ìŒ (í•„í„°ë§Œ ì‚¬ìš©)")

        return query

    def _build_vector_search(
        self,
        query_vector: List[float],
        demographic_filters: List[str],
        k: int
    ) -> Dict:
        """ë²¡í„° ê²€ìƒ‰ ì¿¼ë¦¬ (qa_pairsì—ì„œ ê²€ìƒ‰)"""

        # ì°¸ê³ : qa_pairsì— answer_vectorê°€ ì—†ìœ¼ë©´ ë²¡í„° ê²€ìƒ‰ ë¶ˆê°€
        # í˜„ì¬ëŠ” í‚¤ì›Œë“œ ê²€ìƒ‰ìœ¼ë¡œ fallback
        logger.warning("ë²¡í„° ê²€ìƒ‰ì€ qa_pairsì— answer_vector í•„ë“œê°€ í•„ìš”í•©ë‹ˆë‹¤. í‚¤ì›Œë“œ ê²€ìƒ‰ë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤.")

        # ì„ì‹œë¡œ í‚¤ì›Œë“œ ê²€ìƒ‰ ë°˜í™˜
        return self._build_keyword_search(
            {"must": [], "should": [], "must_not": []},
            demographic_filters
        )

    def _build_weighted_hybrid(
        self,
        keyword_query: Dict,
        vector_query: Dict,
        alpha: float,
        size: int
    ) -> Dict:
        """ê°€ì¤‘ í‰ê·  ë°©ì‹ í•˜ì´ë¸Œë¦¬ë“œ (Fallback)"""

        # alpha = 0: í‚¤ì›Œë“œë§Œ, alpha = 1: ë²¡í„°ë§Œ
        keyword_weight = 1.0 - alpha
        vector_weight = alpha

        query = {
            "query": {
                "bool": {
                    "should": [
                        {
                            "constant_score": {
                                "filter": keyword_query,
                                "boost": keyword_weight
                            }
                        },
                        {
                            "constant_score": {
                                "filter": vector_query,
                                "boost": vector_weight
                            }
                        }
                    ]
                }
            },
            "size": size
        }

        return query

    def _build_keyword_only_query(
        self,
        semantic_terms: Dict[str, List[str]],
        demographic_filters: List[str],
        size: int
    ) -> Dict:
        """í‚¤ì›Œë“œ ê²€ìƒ‰ë§Œ (ë²¡í„° ì—†ìŒ)"""

        keyword_query = self._build_keyword_search(semantic_terms, demographic_filters)

        # ë””ë²„ê¹…: ìƒì„±ëœ ì¿¼ë¦¬ ë¡œê¹…
        logger.info(f"Generated keyword query: {keyword_query}")

        # â­ keyword_queryê°€ Noneì´ë©´ None ë°˜í™˜ (í•„í„°ë§Œ ì‚¬ìš©í•˜ë„ë¡)
        # match_noneì„ ë°˜í™˜í•˜ë©´ í•„í„°ì™€ í•¨ê»˜ mustì— ë“¤ì–´ê°€ì„œ ê²°ê³¼ê°€ 0ê±´ì´ ë¨
        if keyword_query is None:
            # Noneì„ ë°˜í™˜í•˜ë©´ í˜¸ì¶œìê°€ í•„í„°ë§Œ ì‚¬ìš©í•  ìˆ˜ ìˆìŒ
            logger.info("âš ï¸ í‚¤ì›Œë“œ ì¿¼ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤. í•„í„°ë§Œ ì‚¬ìš©í•˜ë„ë¡ None ë°˜í™˜")
            return {
                "query": None,  # None ë°˜í™˜í•˜ì—¬ í•„í„°ë§Œ ì‚¬ìš©í•˜ë„ë¡
                "size": size
            }
        else:
            return {
                "query": keyword_query,
                "size": size
            }


def calculate_rrf_score(
    keyword_results: List[Dict],
    vector_results: List[Dict],
    k: int = 60
) -> List[Dict]:
    """
    ìˆ˜ë™ RRF ì ìˆ˜ ê³„ì‚° (OpenSearch 2.10 ë¯¸ë§Œìš©)
    
    â­ Rank ì •ê·œí™” ì ìš©: ê²°ê³¼ ê°œìˆ˜ì— ê´€ê³„ì—†ì´ ì¼ê´€ëœ ì ìˆ˜ ê³„ì‚°
    RRF ê³µì‹: score = Î£ (1 / (k + normalized_rank))
    normalized_rank = (rank / total_results) * 100

    Args:
        keyword_results: í‚¤ì›Œë“œ ê²€ìƒ‰ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
        vector_results: ë²¡í„° ê²€ìƒ‰ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
        k: RRF ìƒìˆ˜ (ê¸°ë³¸ê°’ 60)

    Returns:
        RRF ì ìˆ˜ë¡œ ì •ë ¬ëœ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
    """

    # ë¬¸ì„œë³„ ì ìˆ˜ ëˆ„ì 
    doc_scores = {}

    # í‚¤ì›Œë“œ ê²°ê³¼ ê°œìˆ˜ (ì •ê·œí™”ìš©)
    keyword_total = len(keyword_results) if keyword_results else 1
    
    # í‚¤ì›Œë“œ ê²°ê³¼
    for rank, result in enumerate(keyword_results, start=1):
        doc_id = result.get('_id', '')
        if not doc_id:
            # _idê°€ ì—†ìœ¼ë©´ ë‹¤ë¥¸ ë°©ë²•ìœ¼ë¡œ ì‹ë³„ ì‹œë„
            doc_id = result.get('id', '') or str(id(result))
        
        # â­ ì •ê·œí™”: rankë¥¼ 0~100 ì‚¬ì´ë¡œ ë³€í™˜
        normalized_rank = (rank / keyword_total) * 100
        score = 1.0 / (k + normalized_rank)

        if doc_id not in doc_scores:
            doc_scores[doc_id] = {
                'doc': result,
                'keyword_rank': rank,
                'keyword_normalized_rank': normalized_rank,
                'keyword_score': score,
                'vector_rank': None,
                'vector_normalized_rank': None,
                'vector_score': 0.0,
                'rrf_score': score
            }
        else:
            doc_scores[doc_id]['keyword_rank'] = rank
            doc_scores[doc_id]['keyword_normalized_rank'] = normalized_rank
            doc_scores[doc_id]['keyword_score'] = score
            doc_scores[doc_id]['rrf_score'] += score

    # ë²¡í„° ê²°ê³¼ ê°œìˆ˜ (ì •ê·œí™”ìš©)
    vector_total = len(vector_results) if vector_results else 1
    
    # ë²¡í„° ê²°ê³¼
    for rank, result in enumerate(vector_results, start=1):
        doc_id = result.get('_id', '')
        if not doc_id:
            # _idê°€ ì—†ìœ¼ë©´ ë‹¤ë¥¸ ë°©ë²•ìœ¼ë¡œ ì‹ë³„ ì‹œë„
            doc_id = result.get('id', '') or str(id(result))
        
        # â­ ì •ê·œí™”: rankë¥¼ 0~100 ì‚¬ì´ë¡œ ë³€í™˜
        normalized_rank = (rank / vector_total) * 100
        score = 1.0 / (k + normalized_rank)

        if doc_id not in doc_scores:
            doc_scores[doc_id] = {
                'doc': result,
                'keyword_rank': None,
                'keyword_normalized_rank': None,
                'keyword_score': 0.0,
                'vector_rank': rank,
                'vector_normalized_rank': normalized_rank,
                'vector_score': score,
                'rrf_score': score
            }
        else:
            doc_scores[doc_id]['vector_rank'] = rank
            doc_scores[doc_id]['vector_normalized_rank'] = normalized_rank
            doc_scores[doc_id]['vector_score'] = score
            doc_scores[doc_id]['rrf_score'] += score

    # RRF ì ìˆ˜ë¡œ ì •ë ¬
    ranked = sorted(doc_scores.values(), key=lambda x: x['rrf_score'], reverse=True)

    # ê²°ê³¼ êµ¬ì„±
    results = []
    for item in ranked:
        doc = item['doc'].copy()
        doc['_score'] = item['rrf_score']
        doc['rrf_score'] = item['rrf_score']  # í˜¸í™˜ì„±ì„ ìœ„í•´ ì¶”ê°€
        doc['_rrf_details'] = {
            'keyword_rank': item['keyword_rank'],
            'keyword_normalized_rank': item.get('keyword_normalized_rank'),
            'vector_rank': item['vector_rank'],
            'vector_normalized_rank': item.get('vector_normalized_rank'),
            'keyword_score': item['keyword_score'],
            'vector_score': item['vector_score']
        }
        results.append(doc)

    return results
