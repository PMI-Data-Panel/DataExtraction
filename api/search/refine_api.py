"""ì¬ì§ˆì˜ API - ì´ì „ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ê¸°ë°˜ìœ¼ë¡œ LLM ì¬ë¶„ì„

ì´ ëª¨ë“ˆì€ Redisì— ì €ì¥ëœ ì´ì „ ê²€ìƒ‰ ê²°ê³¼ì˜ user_idë“¤ì„ ê°€ì ¸ì™€ì„œ
í•´ë‹¹ ì‚¬ìš©ìë“¤ì˜ ë°ì´í„°ë§Œìœ¼ë¡œ LLMì´ ì¬ë¶„ì„í•˜ëŠ” ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.
"""
import json
import logging
import re
from typing import List, Dict, Any, Optional, Tuple
from fastapi import APIRouter, HTTPException, Depends
from pydantic import BaseModel, Field
from opensearchpy import OpenSearch

from ..search_api import _utc_now_iso

logger = logging.getLogger(__name__)

router = APIRouter(
    prefix="/search/refine",
    tags=["Search Refine"]
)

# ëŸ°íƒ€ì„ ì˜ì¡´ì„± (main_api.pyì—ì„œ ì£¼ì…ë¨)
router.redis_client = None  # type: ignore[attr-defined]
router.os_client = None  # type: ignore[attr-defined]
router.anthropic_client = None  # type: ignore[attr-defined]
router.config = None  # type: ignore[attr-defined]
router.conversation_history_prefix = None  # type: ignore[attr-defined]


class RefineQueryRequest(BaseModel):
    """ì¬ì§ˆì˜ ìš”ì²­"""
    session_id: str = Field(..., description="ì„¸ì…˜ ID (ì´ì „ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ê°€ì ¸ì˜¬ ì„¸ì…˜)")
    query: str = Field(..., description="ì¬ì§ˆì˜ ì§ˆë¬¸ (ì˜ˆ: 'ì´ ì‚¬ëŒë“¤ì˜ ê³µí†µì ì€?', 'ì´ ì¤‘ì—ì„œ í¡ì—°ìëŠ”?')")
    max_user_ids: int = Field(default=10, ge=1, le=50, description="ë¶„ì„í•  ìµœëŒ€ user_id ìˆ˜ (ê¸°ë³¸ê°’: 10)")
    llm_instructions: Optional[str] = Field(
        default=None,
        description="LLM ë¶„ì„ ì‹œ ì¶”ê°€ ì§€ì¹¨"
    )


class RefineQueryResponse(BaseModel):
    """ì¬ì§ˆì˜ ì‘ë‹µ"""
    session_id: str
    previous_query: Optional[str] = None
    previous_top_user_ids: List[str] = Field(default_factory=list)
    analyzed_user_ids: List[str] = Field(default_factory=list)
    user_data_count: int = 0
    llm_analysis: Dict[str, Any] = Field(default_factory=dict)
    took_ms: int


def _get_top_user_ids_from_session(session_id: str) -> Tuple[Optional[str], List[str]]:
    """Redisì—ì„œ ì„¸ì…˜ì˜ ì´ì „ ê²€ìƒ‰ ê²°ê³¼ì—ì„œ top_user_ids ì¶”ì¶œ
    
    Returns:
        (ì´ì „_ì§ˆë¬¸, top_user_ids_ë¦¬ìŠ¤íŠ¸)
    """
    redis_client = getattr(router, "redis_client", None)
    if not redis_client:
        logger.warning("Redis í´ë¼ì´ì–¸íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return None, []
    
    conversation_prefix = getattr(router, "conversation_history_prefix", "chat:session")
    conversation_key = f"{conversation_prefix}:{session_id}"
    
    try:
        # Redisì—ì„œ ìµœê·¼ ë©”ì‹œì§€ë“¤ ê°€ì ¸ì˜¤ê¸° (ìµœëŒ€ 50ê°œ)
        raw_items = redis_client.lrange(conversation_key, -50, -1)
        if not raw_items:
            logger.warning(f"ì„¸ì…˜ {session_id}ì˜ ëŒ€í™” íˆìŠ¤í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return None, []
        
        previous_query = None
        top_user_ids = []
        
        # ì—­ìˆœìœ¼ë¡œ ìˆœíšŒí•˜ì—¬ ê°€ì¥ ìµœê·¼ assistant ì‘ë‹µì—ì„œ top_user_ids ì¶”ì¶œ
        for item in reversed(raw_items):
            try:
                payload = json.loads(item)
                role = payload.get("role")
                content = payload.get("content")
                
                if role == "assistant" and content:
                    # contentê°€ ë¬¸ìì—´ì´ë©´ JSON íŒŒì‹± ì‹œë„
                    if isinstance(content, str):
                        try:
                            content = json.loads(content)
                        except:
                            pass
                    
                    # top_user_ids ì¶”ì¶œ
                    if isinstance(content, dict):
                        ids = content.get("top_user_ids", [])
                        if ids:
                            top_user_ids = ids
                            break
                
                elif role == "user" and content and not previous_query:
                    # ê°€ì¥ ìµœê·¼ user ì§ˆë¬¸ ì €ì¥
                    if isinstance(content, str):
                        previous_query = content
                    else:
                        previous_query = str(content)
            
            except Exception as e:
                logger.debug(f"ë©”ì‹œì§€ íŒŒì‹± ì‹¤íŒ¨: {e}")
                continue
        
        return previous_query, top_user_ids
    
    except Exception as e:
        logger.error(f"Redisì—ì„œ ì„¸ì…˜ ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨: {e}")
        return None, []


def _fetch_user_data_from_opensearch(
    user_ids: List[str],
    index_name: str = "survey_responses_merged",
    os_client: Optional[OpenSearch] = None
) -> List[Dict[str, Any]]:
    """OpenSearchì—ì„œ user_idë“¤ì˜ ìƒì„¸ ë°ì´í„° ì¡°íšŒ"""
    if not os_client:
        os_client = getattr(router, "os_client", None)
    
    if not os_client or not os_client.ping():
        raise HTTPException(
            status_code=503,
            detail="OpenSearch ì„œë²„ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        )
    
    if not user_ids:
        return []
    
    try:
        # mgetìœ¼ë¡œ ì—¬ëŸ¬ ë¬¸ì„œ í•œ ë²ˆì— ì¡°íšŒ
        mget_body = [{"_index": index_name, "_id": uid} for uid in user_ids]
        response = os_client.mget(
            body={"docs": mget_body},
            _source=True,
            ignore=[404]
        )
        
        user_data = []
        for doc in response.get("docs", []):
            if doc.get("found"):
                source = doc.get("_source", {})
                user_id = doc.get("_id")
                if user_id and source:
                    user_data.append({
                        "user_id": user_id,
                        **source
                    })
        
        return user_data
    
    except Exception as e:
        logger.error(f"OpenSearchì—ì„œ user ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨: {str(e)}"
        )


def _prepare_data_for_llm(user_data: List[Dict[str, Any]], max_chars: int = 15000) -> List[Dict[str, Any]]:
    """LLMì— ì „ë‹¬í•  ë°ì´í„° ì¤€ë¹„ (í† í° ì œí•œ ê³ ë ¤)"""
    prepared = []
    total_chars = 0
    
    for data in user_data:
        # í•µì‹¬ ì •ë³´ë§Œ ì¶”ì¶œ
        item = {
            "user_id": data.get("user_id"),
            "demographic_info": data.get("demographic_info") or data.get("metadata", {}),
            "behavioral_info": data.get("behavioral_info", {}),
            "qa_pairs": (data.get("qa_pairs") or [])[:5],  # ìµœëŒ€ 5ê°œë§Œ
        }
        
        serialized = json.dumps(item, ensure_ascii=False)
        if total_chars + len(serialized) > max_chars:
            break
        
        prepared.append(item)
        total_chars += len(serialized)
    
    return prepared


def _call_llm_for_refinement(
    previous_query: Optional[str],
    new_query: str,
    user_data: List[Dict[str, Any]],
    instructions: Optional[str] = None
) -> Dict[str, Any]:
    """LLMì— ì¬ì§ˆì˜ ìš”ì²­"""
    anthropic_client = getattr(router, "anthropic_client", None)
    if not anthropic_client:
        raise HTTPException(
            status_code=503,
            detail="Anthropic í´ë¼ì´ì–¸íŠ¸ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
        )
    
    config = getattr(router, "config", None)
    if not config:
        from rag_query_analyzer.config import get_config
        config = get_config()
    
    model_name = getattr(config, "CLAUDE_MODEL", "claude-3-5-sonnet-20241022")
    
    # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
    context_parts = []
    
    context_parts.append("ë‹¹ì‹ ì€ ì„¤ë¬¸ì¡°ì‚¬ ë°ì´í„° ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ ì‚¬ìš©ì ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ ì§ˆë¬¸ì— ëŒ€í•œ ìƒì„¸í•œ ë‹µë³€ì„ ë¬¸ì¥ í˜•íƒœë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.")
    context_parts.append("")
    
    if previous_query:
        context_parts.append(f"ì´ì „ ê²€ìƒ‰ ì§ˆë¬¸: {previous_query}")
        context_parts.append("ì´ì „ ê²€ìƒ‰ ê²°ê³¼ì—ì„œ ì¶”ì¶œí•œ ì‚¬ìš©ì ë°ì´í„°ë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”.")
    else:
        context_parts.append("ë‹¤ìŒ ì‚¬ìš©ì ë°ì´í„°ë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”.")
    
    context_parts.append("")
    context_parts.append(f"ìƒˆë¡œìš´ ì§ˆë¬¸: {new_query}")
    context_parts.append("")
    
    if instructions:
        context_parts.append(f"ì¶”ê°€ ì§€ì¹¨: {instructions}")
        context_parts.append("")
    
    context_parts.append("ì‚¬ìš©ì ë°ì´í„°:")
    context_parts.append(json.dumps(user_data, ensure_ascii=False, indent=2))
    context_parts.append("")
    context_parts.append("ìš”êµ¬ì‚¬í•­:")
    context_parts.append("- ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì„ ìì—°ìŠ¤ëŸ¬ìš´ ë¬¸ì¥ í˜•íƒœë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.")
    context_parts.append("- ë°ì´í„°ì—ì„œ ë°œê²¬í•œ íŒ¨í„´, ê³µí†µì , íŠ¹ì§• ë“±ì„ êµ¬ì²´ì ìœ¼ë¡œ ì„¤ëª…í•´ì£¼ì„¸ìš”.")
    context_parts.append("- ê°€ëŠ¥í•˜ë©´ ë¹„ìœ¨ì´ë‚˜ ë¶„í¬ë¥¼ í¬í•¨í•´ì£¼ì„¸ìš” (ì˜ˆ: 'ëŒ€ë¶€ë¶„ì´...', 'ì „ì²´ì˜ 60%ê°€...', 'ìƒë‹¹ìˆ˜ê°€...').")
    context_parts.append("- ê°„ë‹¨í•œ í‚¤ì›Œë“œë‚˜ ë¦¬ìŠ¤íŠ¸ê°€ ì•„ë‹Œ, ì™„ì „í•œ ë¬¸ì¥ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.")
    context_parts.append("- ë‹µë³€ì€ 200ì ì´ìƒ 1000ì ì´ë‚´ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.")
    context_parts.append("- ì‚¬ìš©ì ìˆ˜ë¥¼ ì§ì ‘ì ìœ¼ë¡œ ì–¸ê¸‰í•˜ì§€ ë§ˆì„¸ìš” (ì˜ˆ: '5ëª…ì˜', '3ëª…ì´' ë“±).")
    
    prompt = "\n".join(context_parts)
    
    # LLM í˜¸ì¶œ
    try:
        message = anthropic_client.messages.create(
            model=model_name,
            max_tokens=3000,
            temperature=0.3,
            messages=[{"role": "user", "content": prompt}],
        )
        
        content = ""
        if message and getattr(message, "content", None):
            parts = getattr(message, "content", [])
            if parts:
                first = parts[0]
                content = getattr(first, "text", "") or ""
        
        # â­ ì¤„ë°”ê¿ˆ ë¬¸ì ì²˜ë¦¬: \n\nì„ ê³µë°±ìœ¼ë¡œ ì¹˜í™˜í•˜ì—¬ JSON ì‘ë‹µì—ì„œ ê¹”ë”í•˜ê²Œ í‘œì‹œ
        if content:
            # ì—°ì†ëœ ì¤„ë°”ê¿ˆ(\n\n, \n\n\n ë“±)ì„ í•˜ë‚˜ì˜ ê³µë°±ìœ¼ë¡œ ì¹˜í™˜
            content = re.sub(r'\n+', ' ', content)
            # ì—°ì†ëœ ê³µë°±ì„ í•˜ë‚˜ë¡œ ì •ë¦¬
            content = re.sub(r'\s+', ' ', content)
            # ì•ë’¤ ê³µë°± ì œê±°
            content = content.strip()
        
        return {
            "model": model_name,
            "generated_at": _utc_now_iso(),
            "analysis": content,
            "user_count": len(user_data),
        }
    
    except Exception as e:
        logger.error(f"LLM ì¬ì§ˆì˜ ì‹¤íŒ¨: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"LLM ë¶„ì„ ì‹¤íŒ¨: {str(e)}"
        )


@router.post("/query", response_model=RefineQueryResponse, summary="ì¬ì§ˆì˜ - ì´ì „ ê²€ìƒ‰ ê²°ê³¼ ê¸°ë°˜ LLM ì¬ë¶„ì„")
async def refine_query(
    request: RefineQueryRequest,
    os_client: OpenSearch = Depends(lambda: router.os_client),
):
    """
    ì´ì „ ê²€ìƒ‰ ê²°ê³¼ì˜ user_idë“¤ì„ ê°€ì ¸ì™€ì„œ í•´ë‹¹ ì‚¬ìš©ìë“¤ì˜ ë°ì´í„°ë§Œìœ¼ë¡œ LLM ì¬ë¶„ì„
    
    íë¦„:
    1. Redisì—ì„œ session_idì˜ ì´ì „ ê²€ìƒ‰ ê²°ê³¼ì—ì„œ top_user_ids ì¶”ì¶œ
    2. survey_responses_merged ì¸ë±ìŠ¤ì—ì„œ í•´ë‹¹ user_idë“¤ì˜ ìƒì„¸ ë°ì´í„° ì¡°íšŒ
    3. ìƒìœ„ Nê°œ(ê¸°ë³¸ 10ê°œ)ë§Œ ì„ íƒ
    4. LLMì— ì¬ì§ˆì˜ í”„ë¡¬í”„íŠ¸ ì „ë‹¬í•˜ì—¬ ë¶„ì„
    5. ê²°ê³¼ ë°˜í™˜
    
    ì˜ˆì‹œ:
    - ì´ì „ ê²€ìƒ‰: "30ëŒ€ ë‚¨ì„±"
    - ì¬ì§ˆì˜: "ì´ ì‚¬ëŒë“¤ì˜ ê³µí†µì ì€?"
    - ì¬ì§ˆì˜: "ì´ ì¤‘ì—ì„œ í¡ì—°ìëŠ” ëª‡ ëª…ì¸ê°€ìš”?"
    """
    import time
    start_time = time.time()
    
    try:
        # 1. Redisì—ì„œ ì´ì „ ê²€ìƒ‰ ê²°ê³¼ì˜ top_user_ids ê°€ì ¸ì˜¤ê¸°
        logger.info(f"ğŸ” ì„¸ì…˜ {request.session_id}ì—ì„œ ì´ì „ ê²€ìƒ‰ ê²°ê³¼ ì¡°íšŒ ì¤‘...")
        previous_query, top_user_ids = _get_top_user_ids_from_session(request.session_id)
        
        if not top_user_ids:
            raise HTTPException(
                status_code=404,
                detail=f"ì„¸ì…˜ {request.session_id}ì—ì„œ ì´ì „ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ê²€ìƒ‰ì„ ìˆ˜í–‰í•´ì£¼ì„¸ìš”."
            )
        
        logger.info(f"  âœ… ì´ì „ ì§ˆë¬¸: {previous_query}")
        logger.info(f"  âœ… ë°œê²¬ëœ user_id: {len(top_user_ids)}ê°œ")
        
        # 2. ìƒìœ„ Nê°œë§Œ ì„ íƒ
        selected_user_ids = top_user_ids[:request.max_user_ids]
        logger.info(f"  âœ… ë¶„ì„ ëŒ€ìƒ: {len(selected_user_ids)}ê°œ (ìƒìœ„ {request.max_user_ids}ê°œ)")
        
        # 3. OpenSearchì—ì„œ user_idë“¤ì˜ ìƒì„¸ ë°ì´í„° ì¡°íšŒ
        logger.info(f"ğŸ“Š survey_responses_mergedì—ì„œ {len(selected_user_ids)}ê°œ user_id ë°ì´í„° ì¡°íšŒ ì¤‘...")
        user_data = _fetch_user_data_from_opensearch(
            user_ids=selected_user_ids,
            index_name="survey_responses_merged",
            os_client=os_client
        )
        
        if not user_data:
            raise HTTPException(
                status_code=404,
                detail=f"user_id {selected_user_ids}ì— í•´ë‹¹í•˜ëŠ” ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            )
        
        logger.info(f"  âœ… ì¡°íšŒëœ ë°ì´í„°: {len(user_data)}ê°œ")
        
        # 4. LLMì— ì „ë‹¬í•  ë°ì´í„° ì¤€ë¹„
        prepared_data = _prepare_data_for_llm(user_data, max_chars=15000)
        logger.info(f"  âœ… LLM ì „ë‹¬ ë°ì´í„°: {len(prepared_data)}ê°œ (í† í° ì œí•œ ê³ ë ¤)")
        
        # 5. LLM ì¬ë¶„ì„
        logger.info(f"ğŸ¤– LLM ì¬ë¶„ì„ ì¤‘...")
        llm_result = _call_llm_for_refinement(
            previous_query=previous_query,
            new_query=request.query,
            user_data=prepared_data,
            instructions=request.llm_instructions
        )
        
        took_ms = int((time.time() - start_time) * 1000)
        
        logger.info(f"âœ… ì¬ì§ˆì˜ ì™„ë£Œ: {took_ms}ms")
        
        return RefineQueryResponse(
            session_id=request.session_id,
            previous_query=previous_query,
            previous_top_user_ids=top_user_ids,
            analyzed_user_ids=selected_user_ids,
            user_data_count=len(user_data),
            llm_analysis=llm_result,
            took_ms=took_ms,
        )
    
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"ì¬ì§ˆì˜ ì¤‘ ì˜¤ë¥˜: {e}", exc_info=True)
        raise HTTPException(
            status_code=500,
            detail=f"ì¬ì§ˆì˜ ì‹¤íŒ¨: {str(e)}"
        )

