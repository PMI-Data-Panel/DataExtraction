import logging
from elasticsearch.helpers import bulk
from ..config import get_config, Config
from ..models.query import QueryAnalysis
from typing import List, Dict, Optional, Any

logger = logging.getLogger(__name__)

def create_index_if_not_exists(es_client, index_name: str):
    """
    Elasticsearchì— íŠ¹ì • ì¸ë±ìŠ¤ê°€ ì¡´ì¬í•˜ì§€ ì•Šìœ¼ë©´,
    'ì‚¬ìš©ì' ë‹¨ìœ„ì˜ nested êµ¬ì¡°ê°€ ì ìš©ëœ ë§¤í•‘ìœ¼ë¡œ ìƒˆ ì¸ë±ìŠ¤ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    """
    if not es_client.indices.exists(index=index_name):
        logger.info(f"âœ¨ '{index_name}' ì¸ë±ìŠ¤ê°€ ì—†ì–´ ìƒˆë¡œ ìƒì„±í•©ë‹ˆë‹¤.")
        config = get_config()

        mappings = {
            "properties": {
                "user_id": {"type": "keyword"},
                "demographics": {
                    "type": "object",
                    "enabled": True
                },
                "other_objectives": {
                    "type": "object",
                    "enabled": True
                },
                "subjective_responses": {
                    "type": "nested",
                    "properties": {
                        "q_text": {"type": "text", "analyzer": "nori"},
                        "q_code": {"type": "keyword"},
                        "q_category": {"type": "keyword"},
                        "answer_text": {"type": "text", "analyzer": "nori"},
                        "answer_vector": {
                            "type": "dense_vector",
                            "dims": config.EMBEDDING_DIM,
                        },
                        "answer_length": {"type": "integer"}
                    },
                },
                "all_subjective_text": {
                    "type": "text",
                    "analyzer": "nori"
                },
                "metadata": {
                    "type": "object",
                    "properties": {
                        "timestamp": {"type": "date"},
                        "total_questions": {"type": "integer"},
                        "demographic_count": {"type": "integer"},
                        "objective_count": {"type": "integer"},
                        "subjective_count": {"type": "integer"},
                        "avg_answer_length": {"type": "float"}
                    }
                }
            }
        }

        try:
            es_client.indices.create(index=index_name, mappings=mappings)
            logger.info(f"ğŸ‘ '{index_name}' ì¸ë±ìŠ¤ ìƒì„± ì™„ë£Œ (ì‚¬ìš©ì ë‹¨ìœ„ Nested êµ¬ì¡° ì ìš©).")
        except Exception as e:
            logger.error(f"ğŸš¨ '{index_name}' ì¸ë±ìŠ¤ ìƒì„± ì‹¤íŒ¨: {e}")
            raise

def bulk_index_data(es_client, actions: list):
    """Elasticsearchì— ë°ì´í„°ë¥¼ ëŒ€ëŸ‰ìœ¼ë¡œ ìƒ‰ì¸í•˜ëŠ” í•¨ìˆ˜"""
    if not actions:
        return 0, []
    try:
        success, failed = bulk(es_client, actions, raise_on_error=False, refresh=True)
        if failed:
            logger.warning(f"ğŸš¨ {len(failed)}ê°œì˜ ë¬¸ì„œ ìƒ‰ì¸ ì‹¤íŒ¨.")
        return success, failed
    except Exception as e:
        logger.error(f"ğŸš¨ ë²Œí¬ ìƒ‰ì¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        raise

class ElasticsearchQueryBuilder:
    """ì¿¼ë¦¬ ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ Elasticsearch ì¿¼ë¦¬ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    def __init__(self, config: Config):
        self.config = config

    def _get_keyword_query(self, term: str) -> Dict:
        """ë‹¨ì¼ í‚¤ì›Œë“œì— ëŒ€í•œ ë©€í‹°-ë§¤ì¹˜ ì¿¼ë¦¬ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
        return {
            "multi_match": {
                "query": term,
                "fields": ["qa_pairs.q_text", "qa_pairs.answer_text"]
            }
        }

    def build_complete_request(self, analysis: QueryAnalysis, query_vector: Optional[List[float]] = None, size: int = 10, filters: Optional[List[Dict]] = None) -> Dict[str, Any]:
        """ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì „ì²´ ES ê²€ìƒ‰ ìš”ì²­ ë³¸ë¬¸ì„ ìƒì„±í•©ë‹ˆë‹¤."""
        
        # ê° í‚¤ì›Œë“œ ì¡°ê±´ì„ ë³„ê°œì˜ nested ì¿¼ë¦¬ë¡œ ìƒì„±
        must_clauses = [
            {"nested": {"path": "qa_pairs", "query": self._get_keyword_query(term), "inner_hits": {"name": f"hit_{term}"}}}
            for term in analysis.must_terms
        ]
        should_clauses = [
            {"nested": {"path": "qa_pairs", "query": self._get_keyword_query(term), "inner_hits": {"name": f"hit_{term}"}}}
            for term in analysis.should_terms
        ]
        must_not_clauses = [
            {"nested": {"path": "qa_pairs", "query": self._get_keyword_query(term)}}
            for term in analysis.must_not_terms
        ]

        if filters:
            must_clauses.extend(filters)

        # ìµœì¢… bool ì¿¼ë¦¬
        final_query = {
            "bool": {
                "must": must_clauses,
                "should": should_clauses,
                "must_not": must_not_clauses
            }
        }
        
        if not any(final_query["bool"].values()):
            final_query = {"match_all": {}}

        # k-NN ë²¡í„° ê²€ìƒ‰ ì¿¼ë¦¬ ì¶”ê°€ (Hybrid ê²€ìƒ‰)
        if query_vector and analysis.intent in ["hybrid", "semantic_search"]:
            knn_query = {
                "field": "qa_pairs.answer_vector",
                "query_vector": query_vector,
                "k": size,
                "num_candidates": self.config.INITIAL_SEARCH_SIZE,
                "inner_hits": {
                    "_source": ["qa_pairs.embedding_text"]
                }
            }
            
            if final_query != {"match_all": {}}:
                knn_query["filter"] = final_query

            request_body = {
                "knn": knn_query,
                "size": size
            }
            
            if analysis.intent == "hybrid":
                request_body["query"] = final_query

            return request_body
        else:
            # í‚¤ì›Œë“œ ê²€ìƒ‰ë§Œ ì‚¬ìš©
            return {
                "query": final_query,
                "size": size
            }