"""OpenSearch Ïú†Ìã∏Î¶¨Ìã∞ Î∞è Ïù∏Îç±Ïä§ Í¥ÄÎ¶¨"""
import logging
from typing import List, Dict, Any
from opensearchpy import OpenSearch
from opensearchpy.helpers import bulk
from ..config import Config

logger = logging.getLogger(__name__)


def create_opensearch_client(config: Config) -> OpenSearch:
    """OpenSearch ÌÅ¥ÎùºÏù¥Ïñ∏Ìä∏ ÏÉùÏÑ±"""
    client = OpenSearch(
        hosts=[{
            "host": config.OPENSEARCH_HOST,
            "port": config.OPENSEARCH_PORT
        }],
        http_auth=(config.OPENSEARCH_USER, config.OPENSEARCH_PASSWORD),
        use_ssl=config.OPENSEARCH_USE_SSL,
        verify_certs=config.OPENSEARCH_VERIFY_CERTS,
        ssl_assert_hostname=config.OPENSEARCH_SSL_ASSERT_HOSTNAME,
        ssl_show_warn=False,
<<<<<<< HEAD
        timeout=180,  # ÎåÄÎüâ Îç∞Ïù¥ÌÑ∞ Ï°∞Ìöå ÎåÄÏùë (Ï†ÑÏ≤¥ Îç∞Ïù¥ÌÑ∞ ÏïΩ 35000Í∞ú)
=======
        timeout=30,
>>>>>>> 30bed4e1b5046741eeec00de15bff537a5ecb047
        max_retries=3,
        retry_on_timeout=True
    )

    # Ïó∞Í≤∞ ÌÖåÏä§Ìä∏
    try:
        info = client.info()
        logger.info(f"‚úÖ OpenSearch Ïó∞Í≤∞ ÏÑ±Í≥µ: v{info['version']['number']}")
        return client
    except Exception as e:
        logger.error(f"‚ùå OpenSearch Ïó∞Í≤∞ Ïã§Ìå®: {e}")
        raise


<<<<<<< HEAD
def ensure_max_result_window(client: OpenSearch, index_name: str, max_result_window: int = 50000) -> bool:
    """
    Ïù∏Îç±Ïä§Ïùò max_result_window ÏÑ§Ï†ïÏùÑ ÌôïÏù∏ÌïòÍ≥† ÌïÑÏöîÏãú ÏóÖÎç∞Ïù¥Ìä∏
    
    Args:
        client: OpenSearch ÌÅ¥ÎùºÏù¥Ïñ∏Ìä∏
        index_name: Ïù∏Îç±Ïä§ Ïù¥Î¶Ñ
        max_result_window: ÏÑ§Ï†ïÌï† ÏµúÎåÄ Í≤∞Í≥º Ï∞Ω ÌÅ¨Í∏∞ (Í∏∞Î≥∏Í∞í: 50000)
    
    Returns:
        ÏÑ§Ï†ïÏù¥ ÏÑ±Í≥µÏ†ÅÏúºÎ°ú ÏóÖÎç∞Ïù¥Ìä∏ÎêòÏóàÍ±∞ÎÇò Ïù¥ÎØ∏ Ï∂©Î∂ÑÌïú Í≤ΩÏö∞ True
    """
    try:
        # ÌòÑÏû¨ Ïù∏Îç±Ïä§ ÏÑ§Ï†ï ÌôïÏù∏
        current_settings = client.indices.get_settings(index=index_name)
        
        if index_name not in current_settings:
            logger.warning(f"‚ö†Ô∏è Ïù∏Îç±Ïä§ {index_name}Í∞Ä Ï°¥Ïû¨ÌïòÏßÄ ÏïäÏäµÎãàÎã§.")
            return False
        
        index_settings = current_settings[index_name]
        current_max_window = index_settings.get('settings', {}).get('index', {}).get('max_result_window')
        
        if current_max_window:
            current_max_window = int(current_max_window)
            if current_max_window >= max_result_window:
                logger.info(f"‚úÖ Ïù∏Îç±Ïä§ {index_name}Ïùò max_result_windowÍ∞Ä Ïù¥ÎØ∏ {current_max_window}Î°ú ÏÑ§Ï†ïÎêòÏñ¥ ÏûàÏäµÎãàÎã§.")
                return True
        
        # ÏÑ§Ï†ï ÏóÖÎç∞Ïù¥Ìä∏
        logger.info(f"üîß Ïù∏Îç±Ïä§ {index_name}Ïùò max_result_windowÎ•º {max_result_window}Î°ú ÏóÖÎç∞Ïù¥Ìä∏ Ï§ë...")
        client.indices.put_settings(
            index=index_name,
            body={
                "index": {
                    "max_result_window": max_result_window
                }
            }
        )
        
        logger.info(f"‚úÖ Ïù∏Îç±Ïä§ {index_name}Ïùò max_result_windowÎ•º {max_result_window}Î°ú ÏóÖÎç∞Ïù¥Ìä∏ ÏôÑÎ£å")
        return True
        
    except Exception as e:
        logger.error(f"‚ùå Ïù∏Îç±Ïä§ {index_name}Ïùò max_result_window ÏÑ§Ï†ï Ïã§Ìå®: {e}")
        return False
=======
def create_hybrid_index(client: OpenSearch, index_name: str, config: Config):
    """ÌïòÏù¥Î∏åÎ¶¨Îìú Íµ¨Ï°∞Ïùò OpenSearch Ïù∏Îç±Ïä§ ÏÉùÏÑ±"""

    # kNN ÌîåÎü¨Í∑∏Ïù∏ ÏÑ§Ï†ï
    settings = {
        "index": {
            "knn": True,  # kNN ÌôúÏÑ±Ìôî
            "knn.algo_param.ef_search": 512,  # Í≤ÄÏÉâ Ïãú ÌÉêÏÉâ Î≤îÏúÑ
            "number_of_shards": 2,
            "number_of_replicas": 1,
            "refresh_interval": "5s"
        },
        "analysis": {
            "analyzer": {
                "korean_analyzer": {
                    "type": "custom",
                    "tokenizer": "nori_tokenizer",
                    "filter": ["nori_part_of_speech", "lowercase", "nori_readingform"]
                }
            }
        }
    }

    # Îß§Ìïë Ï†ïÏùò
    mappings = {
        "properties": {
            "user_id": {
                "type": "keyword"
            },

            # Ïù∏Íµ¨ÌÜµÍ≥Ñ ÌïÑÌÑ∞ (Ï†ïÌôïÌïú term Îß§Ïπ≠)
            "demographics": {
                "properties": {
                    "age_group": {"type": "keyword"},
                    "gender": {"type": "keyword"},
                    "region": {"type": "keyword"},
                    "occupation": {"type": "keyword"},
                    "income": {"type": "keyword"},
                    "education": {"type": "keyword"},
                    "marital_status": {"type": "keyword"},
                    "household": {"type": "keyword"}
                }
            },

            # Í∏∞ÌÉÄ Í∞ùÍ¥ÄÏãù (Ïù∏Íµ¨ÌÜµÍ≥Ñ ÏïÑÎãò)
            "other_objectives": {
                "type": "object",
                "enabled": True
            },

            # Ï£ºÍ¥ÄÏãù ÏùëÎãµ (nested + kNN vector)
            "subjective_responses": {
                "type": "nested",
                "properties": {
                    "q_text": {
                        "type": "text",
                        "analyzer": "korean_analyzer",
                        "fields": {
                            "keyword": {"type": "keyword"}
                        }
                    },
                    "q_code": {"type": "keyword"},
                    "q_category": {"type": "keyword"},
                    "answer_text": {
                        "type": "text",
                        "analyzer": "korean_analyzer",
                        "term_vector": "with_positions_offsets"  # ÌïòÏù¥ÎùºÏù¥ÌåÖÏö©
                    },
                    "answer_vector": {
                        "type": "knn_vector",
                        "dimension": config.EMBEDDING_DIM,
                        "method": {
                            "name": "hnsw",
                            "space_type": "cosinesimil",
                            "engine": config.VECTOR_ENGINE,
                            "parameters": {
                                "ef_construction": config.HNSW_EF_CONSTRUCTION,
                                "m": config.HNSW_M
                            }
                        }
                    },
                    "answer_length": {"type": "integer"}
                }
            },

            # Ï†ÑÏ≤¥ Ï£ºÍ¥ÄÏãù ÌÜµÌï© ÌÖçÏä§Ìä∏ (ÌÇ§ÏõåÎìú Í≤ÄÏÉâÏö©)
            "all_subjective_text": {
                "type": "text",
                "analyzer": "korean_analyzer"
            },

            # Î©îÌÉÄÎç∞Ïù¥ÌÑ∞
            "metadata": {
                "properties": {
                    "timestamp": {"type": "date"},
                    "total_questions": {"type": "integer"},
                    "demographic_count": {"type": "integer"},
                    "objective_count": {"type": "integer"},
                    "subjective_count": {"type": "integer"},
                    "avg_answer_length": {"type": "float"}
                }
            }
        }
    }

    # Ïù∏Îç±Ïä§ ÏÉùÏÑ±
    if client.indices.exists(index=index_name):
        logger.info(f"üëç Ïù∏Îç±Ïä§ '{index_name}' Ïù¥ÎØ∏ Ï°¥Ïû¨")
        return

    try:
        client.indices.create(
            index=index_name,
            body={"settings": settings, "mappings": mappings}
        )
        logger.info(f"‚úÖ OpenSearch ÌïòÏù¥Î∏åÎ¶¨Îìú Ïù∏Îç±Ïä§ '{index_name}' ÏÉùÏÑ± ÏôÑÎ£å")

    except Exception as e:
        logger.error(f"‚ùå Ïù∏Îç±Ïä§ ÏÉùÏÑ± Ïã§Ìå®: {e}")
        raise


def bulk_index_documents(client: OpenSearch, actions: List[Dict[str, Any]]) -> tuple:
    """ÎåÄÎüâ Î¨∏ÏÑú ÏÉâÏù∏"""
    if not actions:
        logger.warning("‚ö†Ô∏è ÏÉâÏù∏Ìï† Î¨∏ÏÑúÍ∞Ä ÏóÜÏäµÎãàÎã§")
        return 0, []

    try:
        success, failed = bulk(
            client,
            actions,
            raise_on_error=False,
            refresh=True,
            request_timeout=60
        )

        if failed:
            logger.warning(f"‚ö†Ô∏è {len(failed)}Í∞ú Î¨∏ÏÑú ÏÉâÏù∏ Ïã§Ìå®")
            for fail in failed[:5]:  # Ï≤òÏùå 5Í∞úÎßå Î°úÍπÖ
                logger.warning(f"   Ïã§Ìå® ÏòàÏãú: {fail}")

        logger.info(f"‚úÖ Î≤åÌÅ¨ ÏÉâÏù∏ ÏôÑÎ£å: ÏÑ±Í≥µ {success}Í∞ú, Ïã§Ìå® {len(failed)}Í∞ú")
        return success, failed

    except Exception as e:
        logger.error(f"‚ùå Î≤åÌÅ¨ ÏÉâÏù∏ Ïò§Î•ò: {e}")
        raise


def warmup_knn_index(client: OpenSearch, index_name: str, dimension: int = 1024):
    """kNN Ïù∏Îç±Ïä§ ÏõåÎ∞çÏóÖ (ÏÑ±Îä• Ìñ•ÏÉÅ)"""
    try:
        client.indices.refresh(index=index_name)

        # ÎçîÎØ∏ Î≤°ÌÑ∞ Í≤ÄÏÉâÏúºÎ°ú Ï∫êÏãú ÏõåÎ∞ç
        dummy_vector = [0.0] * dimension

        client.search(
            index=index_name,
            body={
                "size": 1,
                "query": {
                    "nested": {
                        "path": "subjective_responses",
                        "query": {
                            "knn": {
                                "subjective_responses.answer_vector": {
                                    "vector": dummy_vector,
                                    "k": 1
                                }
                            }
                        }
                    }
                }
            }
        )

        logger.info(f"‚úÖ kNN Ïù∏Îç±Ïä§ ÏõåÎ∞çÏóÖ ÏôÑÎ£å: {index_name}")

    except Exception as e:
        logger.warning(f"‚ö†Ô∏è kNN ÏõåÎ∞çÏóÖ Ïã§Ìå® (Î¨¥Ïãú Í∞ÄÎä•): {e}")


def delete_index(client: OpenSearch, index_name: str):
    """Ïù∏Îç±Ïä§ ÏÇ≠Ï†ú (Ïû¨ÏÉùÏÑ± Ïãú ÏÇ¨Ïö©)"""
    if client.indices.exists(index=index_name):
        client.indices.delete(index=index_name)
        logger.info(f"üóëÔ∏è Ïù∏Îç±Ïä§ '{index_name}' ÏÇ≠Ï†ú ÏôÑÎ£å")
    else:
        logger.info(f"üëç Ïù∏Îç±Ïä§ '{index_name}' Ï°¥Ïû¨ÌïòÏßÄ ÏïäÏùå")


def get_index_stats(client: OpenSearch, index_name: str) -> Dict[str, Any]:
    """Ïù∏Îç±Ïä§ ÌÜµÍ≥Ñ Ï°∞Ìöå"""
    try:
        stats = client.indices.stats(index=index_name)
        count = client.count(index=index_name)

        return {
            "index_name": index_name,
            "doc_count": count['count'],
            "store_size": stats['_all']['total']['store']['size_in_bytes'],
            "store_size_mb": round(stats['_all']['total']['store']['size_in_bytes'] / 1024 / 1024, 2),
            "search_total": stats['_all']['total']['search']['query_total'],
            "search_time_ms": stats['_all']['total']['search']['query_time_in_millis']
        }

    except Exception as e:
        logger.error(f"‚ùå ÌÜµÍ≥Ñ Ï°∞Ìöå Ïã§Ìå®: {e}")
        return {}
>>>>>>> 30bed4e1b5046741eeec00de15bff537a5ecb047
