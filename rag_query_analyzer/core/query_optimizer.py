import os
import json
import logging
import numpy as np
from typing import List, Optional, Dict
from datetime import datetime
from ..models.query import QueryAnalysis, SearchResult
from ..models.logs import QueryPerformanceLog
from ..config import Config

logger = logging.getLogger(__name__)


class QueryOptimizer:
    """í”¼ë“œë°± ê¸°ë°˜ ì¿¼ë¦¬ ìµœì í™”
    
    ê³¼ê±° ì¿¼ë¦¬ ì„±ëŠ¥ì„ í•™ìŠµí•˜ì—¬ ìµœì ì˜ íŒŒë¼ë¯¸í„°ë¥¼ ì¶”ì²œí•©ë‹ˆë‹¤.
    """
    
    def __init__(self, config: Config = None):
        """ì´ˆê¸°í™”
        
        Args:
            config: ì„¤ì • ê°ì²´
        """
        self.config = config or Config()
        self.log_file = self.config.QUERY_LOG_FILE
        self.performance_logs: List[QueryPerformanceLog] = []
        self._load_logs()
        logger.info("QueryOptimizer ì´ˆê¸°í™” ì™„ë£Œ")
    
    def _load_logs(self):
        """ì €ì¥ëœ ë¡œê·¸ ë¶ˆëŸ¬ì˜¤ê¸°"""
        if os.path.exists(self.log_file):
            try:
                with open(self.log_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    self.performance_logs = [
                        QueryPerformanceLog.from_dict(log_data) 
                        for log_data in data
                    ]
                logger.info(f"ğŸ“Š {len(self.performance_logs)}ê°œì˜ ë¡œê·¸ ë¡œë“œ")
            except Exception as e:
                logger.warning(f"ë¡œê·¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
    
    def _save_logs(self):
        """ë¡œê·¸ ì €ì¥"""
        try:
            # ìµœëŒ€ 10000ê°œ ë¡œê·¸ë§Œ ìœ ì§€
            if len(self.performance_logs) > 10000:
                self.performance_logs = self.performance_logs[-10000:]
            
            with open(self.log_file, 'w', encoding='utf-8') as f:
                logs_data = [log.to_dict() for log in self.performance_logs]
                json.dump(logs_data, f, ensure_ascii=False, indent=2)
        except Exception as e:
            logger.error(f"ë¡œê·¸ ì €ì¥ ì‹¤íŒ¨: {e}")
    
    def log_performance(self,
                    query: str,
                    analysis: QueryAnalysis,
                    results: List[SearchResult],
                    user_feedback: Optional[float] = None,
                    auto_evaluated: bool = True):
        """ì¿¼ë¦¬ ì„±ëŠ¥ ë¡œê¹…
        
        Args:
            query: ì›ë³¸ ì¿¼ë¦¬
            analysis: ë¶„ì„ ê²°ê³¼
            results: ê²€ìƒ‰ ê²°ê³¼
            user_feedback: ì‚¬ìš©ì í”¼ë“œë°± (0-1)
            auto_evaluated: ìë™ í‰ê°€ ì—¬ë¶€
        """
        # ìë™ í‰ê°€
        auto_score = self.auto_evaluate_results(results, analysis) if auto_evaluated else 0.0
        
        log = QueryPerformanceLog(
            query=query,
            intent=analysis.intent,
            alpha=analysis.alpha,
            keywords=analysis.must_terms,
            result_quality=user_feedback if user_feedback is not None else auto_score,
            timestamp=datetime.now(),
            execution_time=analysis.execution_time,
            auto_evaluated=auto_evaluated,
            user_feedback=user_feedback,
            result_count=len(results),
            cache_hit=analysis.cache_hit
        )
        
        self.performance_logs.append(log)
        self._save_logs()
        
        quality = user_feedback if user_feedback is not None else auto_score
        logger.info(f"ğŸ“ ì„±ëŠ¥ ë¡œê·¸ ì €ì¥: í’ˆì§ˆ={quality:.2f}")
    
    def auto_evaluate_results(self, 
                            results: List[SearchResult], 
                            analysis: QueryAnalysis) -> float:
        """ê²€ìƒ‰ ê²°ê³¼ í’ˆì§ˆ ìë™ í‰ê°€
        
        Args:
            results: ê²€ìƒ‰ ê²°ê³¼
            analysis: ì¿¼ë¦¬ ë¶„ì„ ê²°ê³¼
            
        Returns:
            í’ˆì§ˆ ì ìˆ˜ (0-1)
        """
        if not results:
            return 0.0
        
        quality_score = 0.0
        
        # 1. ê²°ê³¼ ìˆ˜ í‰ê°€ (30%)
        result_count_score = min(len(results) / 10, 1.0)
        quality_score += 0.3 * result_count_score
        
        # 2. ë¦¬ë­í‚¹ ì ìˆ˜ ë¶„í¬ í‰ê°€ (30%)
        if results and results[0].rerank_score is not None:
            rerank_scores = [r.rerank_score for r in results[:5] 
                        if r.rerank_score is not None]
            if len(rerank_scores) > 1:
                score_variance = np.var(rerank_scores)
                # ë¶„ì‚°ì´ ì ë‹¹íˆ ìˆìœ¼ë©´ ì¢‹ìŒ (ë„ˆë¬´ ì‘ê±°ë‚˜ í¬ë©´ ì•ˆì¢‹ìŒ)
                if 0.05 < score_variance < 0.5:
                    quality_score += 0.3
                else:
                    quality_score += 0.15
        
        # 3. í‚¤ì›Œë“œ ë§¤ì¹­ë¥  í‰ê°€ (40%)
        if analysis.must_terms:
            top_results = results[:min(5, len(results))]
            match_scores = []
            
            for result in top_results:
                text_to_check = f"{result.summary} {str(result.answers)}".lower()
                matched = sum(1 for term in analysis.must_terms 
                            if term.lower() in text_to_check)
                match_rate = matched / len(analysis.must_terms)
                match_scores.append(match_rate)
            
            avg_match_rate = np.mean(match_scores) if match_scores else 0
            quality_score += 0.4 * avg_match_rate
        
        return min(quality_score, 1.0)
    
    def find_optimal_params(self, query: str, top_k: int = 5) -> Optional[Dict]:
        """ìœ ì‚¬í•œ ê³¼ê±° ì¿¼ë¦¬ì˜ ìµœì  íŒŒë¼ë¯¸í„° ì°¾ê¸°
        
        Args:
            query: í˜„ì¬ ì¿¼ë¦¬
            top_k: ì°¸ê³ í•  ìƒìœ„ ì¿¼ë¦¬ ìˆ˜
            
        Returns:
            ìµœì  íŒŒë¼ë¯¸í„° ë”•ì…”ë„ˆë¦¬ ë˜ëŠ” None
        """
        if len(self.performance_logs) < 10:
            return None
        
        # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ê¸°ë°˜ ìœ ì‚¬ë„ ê³„ì‚°
        query_words = set(query.lower().split())
        
        similar_logs = []
        for log in self.performance_logs:
            log_words = set(log.query.lower().split())
            
            # Jaccard ìœ ì‚¬ë„
            if query_words and log_words:
                similarity = len(query_words & log_words) / len(query_words | log_words)
                
                # í’ˆì§ˆì´ ì¢‹ì€ ë¡œê·¸ë§Œ ê³ ë ¤
                if similarity > 0.3 and log.result_quality > 0.5:
                    weighted_score = similarity * log.result_quality
                    similar_logs.append((weighted_score, log))
        
        if not similar_logs:
            return None
        
        # ìƒìœ„ kê°œ ì„ íƒ
        similar_logs.sort(key=lambda x: x[0], reverse=True)
        top_logs = similar_logs[:top_k]
        
        # ê°€ì¤‘ í‰ê·  ê³„ì‚°
        total_weight = sum(score for score, _ in top_logs)
        weighted_alpha = sum(score * log.alpha for score, log in top_logs) / total_weight
        
        # ê³µí†µ í‚¤ì›Œë“œ ì¶”ì¶œ
        keyword_freq = {}
        for score, log in top_logs:
            for keyword in log.keywords:
                keyword_freq[keyword] = keyword_freq.get(keyword, 0) + score
        
        suggested_keywords = sorted(keyword_freq.items(), 
                                key=lambda x: x[1], 
                                reverse=True)[:10]
        
        logger.info(f"ğŸ¯ ìœ ì‚¬ ì¿¼ë¦¬ {len(top_logs)}ê°œ ë°œê²¬")
        
        return {
            "optimal_alpha": weighted_alpha,
            "suggested_keywords": [kw for kw, _ in suggested_keywords],
            "confidence": total_weight / len(top_logs) if top_logs else 0,
            "similar_queries": len(top_logs)
        }