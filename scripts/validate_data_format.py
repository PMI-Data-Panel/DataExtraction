"""
ë°ì´í„° í˜•ì‹ ê²€ì¦ ìŠ¤í¬ë¦½íŠ¸

question_list.csvì™€ response_list.csvì˜ í˜•ì‹ì„ ê²€ì¦í•˜ê³ 
OpenSearch ì¸ë±ì‹±ì— ë¬¸ì œê°€ ì—†ëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤.
"""

import pandas as pd
import logging
from indexer.parser import parse_question_metadata, validate_metadata
from indexer.core import validate_response_data

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


def validate_data_consistency(
    questions_meta: dict,
    response_file: str
) -> dict:
    """
    ì§ˆë¬¸ ë©”íƒ€ë°ì´í„°ì™€ ì‘ë‹µ ë°ì´í„°ì˜ ì¼ê´€ì„±ì„ ê²€ì¦í•©ë‹ˆë‹¤.

    Returns:
        ê²€ì¦ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
    """
    results = {
        "total_questions": len(questions_meta),
        "missing_in_responses": [],
        "extra_in_responses": [],
        "type_issues": [],
        "sample_data": {},
        "overall_status": "âœ… í†µê³¼"
    }

    # ì‘ë‹µ ë°ì´í„° ë¡œë“œ
    logger.info(f"ğŸ“Š ì‘ë‹µ ë°ì´í„° ë¡œë”©: {response_file}")
    df = pd.read_csv(response_file, encoding="utf-8-sig", dtype=str)

    logger.info(f"   - ì‘ë‹µ ìˆ˜: {len(df):,}ê°œ")
    logger.info(f"   - ì»¬ëŸ¼ ìˆ˜: {len(df.columns)}ê°œ")

    # ì»¬ëŸ¼ í™•ì¸
    response_columns = set(df.columns) - {'mb_sn'}
    question_codes = set(questions_meta.keys()) - {'mb_sn'}

    # ì§ˆë¬¸ ë©”íƒ€ë°ì´í„°ì—ëŠ” ìˆì§€ë§Œ ì‘ë‹µì— ì—†ëŠ” ê²ƒ
    missing = question_codes - response_columns
    if missing:
        results["missing_in_responses"] = list(missing)
        logger.warning(f"âš ï¸ ì§ˆë¬¸ ë©”íƒ€ë°ì´í„°ì—ëŠ” ìˆì§€ë§Œ ì‘ë‹µ ë°ì´í„°ì— ì—†ëŠ” ì§ˆë¬¸: {missing}")

    # ì‘ë‹µì—ëŠ” ìˆì§€ë§Œ ì§ˆë¬¸ ë©”íƒ€ë°ì´í„°ì— ì—†ëŠ” ê²ƒ
    extra = response_columns - question_codes
    if extra:
        results["extra_in_responses"] = list(extra)
        logger.warning(f"âš ï¸ ì‘ë‹µ ë°ì´í„°ì—ëŠ” ìˆì§€ë§Œ ì§ˆë¬¸ ë©”íƒ€ë°ì´í„°ì— ì—†ëŠ” ì»¬ëŸ¼: {extra}")

    # ìƒ˜í”Œ ë°ì´í„° ê²€ì¦
    logger.info("\nğŸ“ ìƒ˜í”Œ ë°ì´í„° ê²€ì¦ (ì²« 5ê°œ ì‘ë‹µ):")
    for idx, row in df.head(5).iterrows():
        user_id = row.get('mb_sn')
        logger.info(f"\n   ì‚¬ìš©ì {idx + 1} (ID: {user_id}):")

        sample_qa = []
        for q_code in list(question_codes)[:5]:  # ì²˜ìŒ 5ê°œ ì§ˆë¬¸ë§Œ
            if q_code in df.columns:
                answer = row.get(q_code)
                q_info = questions_meta.get(q_code, {})
                q_type = q_info.get('type', 'Unknown')

                if pd.notna(answer) and str(answer).strip():
                    logger.info(f"      {q_code} ({q_type}): {answer}")
                    sample_qa.append({
                        "q_code": q_code,
                        "q_type": q_type,
                        "answer": str(answer)
                    })

        if idx == 0:
            results["sample_data"] = {
                "user_id": user_id,
                "qa_pairs": sample_qa
            }

    # íƒ€ì…ë³„ í†µê³„
    logger.info("\nğŸ“Š ë°ì´í„° íƒ€ì…ë³„ í†µê³„:")
    type_stats = {}
    for q_code, q_info in questions_meta.items():
        if q_code == 'mb_sn':
            continue

        q_type = q_info.get('type', 'Unknown')
        type_stats[q_type] = type_stats.get(q_type, 0) + 1

    for q_type, count in type_stats.items():
        logger.info(f"   - {q_type}: {count}ê°œ")

    # MULTI íƒ€ì… ê²€ì¦
    logger.info("\nğŸ” MULTI íƒ€ì… ë‹µë³€ í˜•ì‹ ê²€ì¦:")
    multi_questions = [q for q, info in questions_meta.items()
                      if info.get('type') == 'MULTI' and q in df.columns]

    for q_code in multi_questions[:3]:  # ì²˜ìŒ 3ê°œë§Œ
        sample_answers = df[q_code].dropna().head(3)
        logger.info(f"   {q_code}:")
        for answer in sample_answers:
            logger.info(f"      '{answer}'")
            # ì‰¼í‘œë¡œ êµ¬ë¶„ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
            if ',' in str(answer):
                codes = str(answer).split(',')
                logger.info(f"         â†’ {len(codes)}ê°œ ì„ íƒì§€")

    # ìµœì¢… íŒì •
    if missing or extra:
        results["overall_status"] = "âš ï¸ ê²½ê³  (ì¼ë¶€ ë¶ˆì¼ì¹˜)"

    if results["type_issues"]:
        results["overall_status"] = "âŒ ì‹¤íŒ¨ (íƒ€ì… ì˜¤ë¥˜)"

    return results


def main():
    """ë©”ì¸ ê²€ì¦ í•¨ìˆ˜"""

    logger.info("=" * 60)
    logger.info("ğŸ” ë°ì´í„° í˜•ì‹ ê²€ì¦ ì‹œì‘")
    logger.info("=" * 60)

    question_file = "./data/question_list.csv"
    response_file = "./data/response_list.csv"

    try:
        # 1. ì§ˆë¬¸ ë©”íƒ€ë°ì´í„° íŒŒì‹±
        logger.info("\n[1/3] ì§ˆë¬¸ ë©”íƒ€ë°ì´í„° íŒŒì‹± ì¤‘...")
        questions_meta = parse_question_metadata(question_file)

        # 2. ë©”íƒ€ë°ì´í„° ê²€ì¦
        logger.info("\n[2/3] ë©”íƒ€ë°ì´í„° ê²€ì¦ ì¤‘...")
        if not validate_metadata(questions_meta):
            logger.error("âŒ ë©”íƒ€ë°ì´í„° ê²€ì¦ ì‹¤íŒ¨")
            return

        # 3. ì‘ë‹µ ë°ì´í„° ê²€ì¦
        logger.info("\n[3/3] ì‘ë‹µ ë°ì´í„° ê²€ì¦ ì¤‘...")
        df = pd.read_csv(response_file, encoding="utf-8-sig", dtype=str)
        if not validate_response_data(df):
            logger.error("âŒ ì‘ë‹µ ë°ì´í„° ê²€ì¦ ì‹¤íŒ¨")
            return

        # 4. ì¼ê´€ì„± ê²€ì¦
        logger.info("\n[ë³´ë„ˆìŠ¤] ë°ì´í„° ì¼ê´€ì„± ê²€ì¦ ì¤‘...")
        results = validate_data_consistency(questions_meta, response_file)

        # ê²°ê³¼ ì¶œë ¥
        logger.info("\n" + "=" * 60)
        logger.info("ğŸ“‹ ê²€ì¦ ê²°ê³¼ ìš”ì•½")
        logger.info("=" * 60)
        logger.info(f"   ì´ ì§ˆë¬¸ ìˆ˜: {results['total_questions']}ê°œ")
        logger.info(f"   ëˆ„ë½ëœ ì§ˆë¬¸: {len(results['missing_in_responses'])}ê°œ")
        logger.info(f"   ì¶”ê°€ ì»¬ëŸ¼: {len(results['extra_in_responses'])}ê°œ")
        logger.info(f"   ìµœì¢… ìƒíƒœ: {results['overall_status']}")

        if results['missing_in_responses']:
            logger.warning(f"\n   ëˆ„ë½ ëª©ë¡: {results['missing_in_responses'][:10]}")

        if results['extra_in_responses']:
            logger.warning(f"\n   ì¶”ê°€ ëª©ë¡: {results['extra_in_responses'][:10]}")

        logger.info("\n" + "=" * 60)
        logger.info("âœ… ë°ì´í„° í˜•ì‹ ê²€ì¦ ì™„ë£Œ!")
        logger.info("=" * 60)

        # ìƒ˜í”Œ OpenSearch ë¬¸ì„œ ì‹œë®¬ë ˆì´ì…˜ (ìƒˆë¡œìš´ êµ¬ì¡°)
        logger.info("\nğŸ“„ OpenSearch ë¬¸ì„œ ìƒ˜í”Œ (ì‹œë®¬ë ˆì´ì…˜ - ìƒˆ êµ¬ì¡°):")
        logger.info("=" * 60)

        sample_doc = {
            "user_id": results['sample_data'].get('user_id'),
            "timestamp": "2025-01-01T00:00:00",
            "qa_pairs": []
        }

        for qa in results['sample_data'].get('qa_pairs', [])[:5]:
            q_code = qa['q_code']
            q_info = questions_meta.get(q_code, {})
            answer_raw = qa['answer']

            if qa['q_type'] == 'MULTI':
                # MULTI: ê° ì„ íƒì§€ë¥¼ ë³„ë„ qa_pairë¡œ ì €ì¥
                answers = [code.strip() for code in str(answer_raw).split(',') if code.strip()]
                for code in answers:
                    answer_text = q_info['options'].get(code, code)
                    if answer_text:
                        embedding_text = f"{q_info.get('text', '')} ì§ˆë¬¸ì— '{answer_text}'ë¼ê³  ë‹µë³€"
                        sample_doc['qa_pairs'].append({
                            "q_code": q_code,
                            "q_type": qa['q_type'],
                            "q_text": q_info.get('text', ''),
                            "answer_text": answer_text,
                            "embedding_text": embedding_text,
                            "answer_vector": "[1024ì°¨ì› ë²¡í„° - ìƒëµ]"
                        })
            else:
                # SINGLE/Numeric/String: ë‹¨ì¼ qa_pairë¡œ ì €ì¥
                answer_text = answer_raw
                if qa['q_type'] == 'SINGLE' and q_info.get('options'):
                    answer_text = q_info['options'].get(answer_raw, answer_raw)

                embedding_text = f"{q_info.get('text', '')} ì§ˆë¬¸ì— '{answer_text}'ë¼ê³  ë‹µë³€"
                sample_doc['qa_pairs'].append({
                    "q_code": q_code,
                    "q_type": qa['q_type'],
                    "q_text": q_info.get('text', ''),
                    "answer_text": answer_text,
                    "embedding_text": embedding_text,
                    "answer_vector": "[1024ì°¨ì› ë²¡í„° - ìƒëµ]"
                })

        import json
        logger.info(json.dumps(sample_doc, indent=2, ensure_ascii=False))
        logger.info("=" * 60)

        # êµ¬ì¡° ì„¤ëª…
        logger.info("\nğŸ“‹ ìƒˆë¡œìš´ ë°ì´í„° êµ¬ì¡° íŠ¹ì§•:")
        logger.info("=" * 60)
        logger.info("âœ… MULTI íƒ€ì…: ê° ì„ íƒì§€ë¥¼ ë³„ë„ qa_pairs í•­ëª©ìœ¼ë¡œ ì €ì¥")
        logger.info("âœ… í•„ë“œëª…: answer_text (answer ëŒ€ì‹ )")
        logger.info("âœ… embedding_text: 'ì§ˆë¬¸ ~ ë‹µë³€' í˜•ì‹ìœ¼ë¡œ ìƒì„±")
        logger.info("âœ… answer_vector: ëª¨ë“  ë‹µë³€ì— ëŒ€í•´ 1024ì°¨ì› ì„ë² ë”© ìƒì„±")
        logger.info("=" * 60)

    except Exception as e:
        logger.error(f"ğŸš¨ ê²€ì¦ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}", exc_info=True)
        return


if __name__ == "__main__":
    main()
